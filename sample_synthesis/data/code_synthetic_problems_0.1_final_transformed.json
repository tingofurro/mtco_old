[{"problem_id": 82, "category": "string_manipulation", "name": "normalize_license_plate", "domain": "transport", "description": "Remove spaces and dashes, convert letters to uppercase, return standardized plate string.", "verified": true, "reference_solution": "def normalize_license_plate(plate: str) -> str:\n    \"\"\"Return the license plate string without spaces or dashes and with\n    all alphabetical characters in uppercase.\n    Example: \"ab- c 123\" -> \"ABC123\"\"\"    \n    # Remove spaces and dashes then convert the remaining string to uppercase\n    return ''.join(ch for ch in plate if ch not in ' -').upper()", "reference_tests": [{"type": "basic", "inputs": ["abc 123"], "output": "ABC123"}, {"type": "basic", "inputs": ["ab-c- 123"], "output": "ABC123"}, {"type": "edge_case", "inputs": ["ABC123"], "output": "ABC123"}, {"type": "edge_case", "inputs": ["  abc-123  "], "output": "ABC123"}, {"type": "edge_case", "inputs": ["ab@12-c"], "output": "AB@12C"}], "sample_type": "code_synthetic", "shards": [{"shard_id": 3, "shard": "Any letters left should change to big caps format"}, {"shard_id": 4, "shard": "Return the joined result as final plate text input string out string"}, {"shard_id": 1, "shard": "Need to tidy a license string and make it uniform"}, {"shard_id": 2, "shard": "Throw out spaces and dash characters when you see them"}], "task": "code", "task_id": "sharded-synthetic-code-82", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 0.75, "concat-all": {"t-gpt-4.1": [1, 1, 0, 1, 1, 0, 1, 1]}, "shuffle-concat-avg": 0.75, "shuffle-concat-all": {"t-gpt-4.1": [0, 1, 0, 1, 1, 1, 1, 1]}, "sharded-avg": 0.375, "sharded-all": {"t-gpt-4.1": [0, 0, 1, 0, 1, 1, 0, 0]}}, "acceptable": 1, "metadata": {"func_name": "normalize_license_plate"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"\\\"abc 123\\\"\", \"output\": \"\\\"ABC123\\\"\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"\\\"ab-c- 123\\\"\", \"output\": \"\\\"ABC123\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"ABC123\\\"\", \"output\": \"\\\"ABC123\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"  abc-123  \\\"\", \"output\": \"\\\"ABC123\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"ab@12-c\\\"\", \"output\": \"\\\"AB@12C\\\"\", \"testtype\": \"functional\"}]"}, {"problem_id": 5, "category": "list_processing", "name": "rolling_profit_window", "domain": "finance", "description": "Given daily profit integers and window length k, produce list of sums over every consecutive k-day interval. Return empty list if k is larger than data length.", "verified": true, "reference_solution": "def rolling_profit_window(profits, k):\n    # Return an empty list for non-positive window or if window exceeds data length\n    if k <= 0 or k > len(profits):\n        return []\n\n    # Initial window sum\n    window_sum = sum(profits[:k])\n    result = [window_sum]\n\n    # Slide the window across the list\n    for i in range(k, len(profits)):\n        window_sum += profits[i] - profits[i - k]\n        result.append(window_sum)\n\n    return result", "reference_tests": [{"type": "basic", "inputs": [[1, 2, 3, 4, 5], 3], "output": [6, 9, 12]}, {"type": "basic", "inputs": [[10, -2, 3, 5], 2], "output": [8, 1, 8]}, {"type": "edge_case", "inputs": [[1, 2, 3], 3], "output": [6]}, {"type": "edge_case", "inputs": [[4, 1], 5], "output": []}, {"type": "edge_case", "inputs": [[], 1], "output": []}, {"type": "edge_case", "inputs": [[1, 2, 3], 0], "output": []}], "sample_type": "code_synthetic", "shards": [{"shard_id": 1, "shard": "Turn daily profit data into rolling totals"}, {"shard_id": 3, "shard": "For every consecutive k days sum them and collect results"}, {"shard_id": 2, "shard": "Input is list of integers then window length k"}, {"shard_id": 4, "shard": "If k invalid or longer than data output empty list"}], "task": "code", "task_id": "sharded-synthetic-code-5", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.875, "sharded-all": {"t-gpt-4.1": [0, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "rolling_profit_window"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[1, 2, 3, 4, 5]\\n3\", \"output\": \"[6, 9, 12]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[10, -2, 3, 5]\\n2\", \"output\": \"[8, 1, 8]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[1, 2, 3]\\n3\", \"output\": \"[6]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[4, 1]\\n5\", \"output\": \"[]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\\n1\", \"output\": \"[]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[1, 2, 3]\\n0\", \"output\": \"[]\", \"testtype\": \"functional\"}]"}, {"problem_id": 66, "category": "combinatorics", "name": "weather_outfit_options", "domain": "weather", "description": "Given lists of tops, bottoms, and accessories, count outfit combinations where accessories optional but at most two chosen.", "verified": true, "reference_solution": "def weather_outfit_options(tops, bottoms, accessories):\n    \"\"\"Return number of possible outfit combinations.\n    Each outfit must have exactly one top and one bottom.\n    Accessories are optional; you may pick 0, 1 or 2 distinct accessories.\n    \"\"\"\n    # If no tops or bottoms, no outfit can be formed\n    if not tops or not bottoms:\n        return 0\n\n    a = len(accessories)\n    # combinations for picking 0,1,2 accessories without repetition\n    accessory_choices = 1 + a  # choose 0 or 1\n    if a >= 2:\n        accessory_choices += a * (a - 1) // 2  # choose 2 distinct accessories\n    total = len(tops) * len(bottoms) * accessory_choices\n    return total", "reference_tests": [{"type": "basic", "inputs": [["t1", "t2"], ["b1"], ["a1", "a2"]], "output": 8}, {"type": "basic", "inputs": [["top"], ["bottom1", "bottom2", "bottom3"], []], "output": 3}, {"type": "edge_case", "inputs": [["shirt"], ["jeans"], ["watch"]], "output": 2}, {"type": "edge_case", "inputs": [[], ["b1"], ["a1", "a2", "a3"]], "output": 0}, {"type": "edge_case", "inputs": [["t1"], ["b1"], ["a1", "a2", "a3", "a4"]], "output": 11}], "sample_type": "code_synthetic", "shards": [{"shard_id": 1, "shard": "Figure how many outfits you could build from clothing lists"}, {"shard_id": 4, "shard": "Receive lists return single count of distinct outfit possibilities"}, {"shard_id": 2, "shard": "Each outfit must use one top item and one bottom"}, {"shard_id": 3, "shard": "Accessories add zero one or two unique pieces max"}], "task": "code", "task_id": "sharded-synthetic-code-66", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 0.875, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 0, 1, 1]}, "sharded-avg": 0.375, "sharded-all": {"t-gpt-4.1": [0, 0, 1, 1, 0, 1, 0, 0]}}, "acceptable": 1, "metadata": {"func_name": "weather_outfit_options"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[\\\"t1\\\", \\\"t2\\\"]\\n[\\\"b1\\\"]\\n[\\\"a1\\\", \\\"a2\\\"]\", \"output\": \"8\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[\\\"top\\\"]\\n[\\\"bottom1\\\", \\\"bottom2\\\", \\\"bottom3\\\"]\\n[]\", \"output\": \"3\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"shirt\\\"]\\n[\\\"jeans\\\"]\\n[\\\"watch\\\"]\", \"output\": \"2\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\\n[\\\"b1\\\"]\\n[\\\"a1\\\", \\\"a2\\\", \\\"a3\\\"]\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"t1\\\"]\\n[\\\"b1\\\"]\\n[\\\"a1\\\", \\\"a2\\\", \\\"a3\\\", \\\"a4\\\"]\", \"output\": \"11\", \"testtype\": \"functional\"}]"}, {"problem_id": 92, "category": "bitwise", "name": "energy_meter_flag_set", "domain": "energy", "description": "Given integer state, set bit 5 to 1 and clear bit 2. Return new state.", "verified": true, "reference_solution": "def energy_meter_flag_set(state: int) -> int:\n    \"\"\"Set bit 5 (value 32) and clear bit 2 (value 4) of the given integer state.\n\n    Bits are numbered from 0 (least-significant bit). The function returns the\n    modified state leaving all other bits unchanged.\n    \"\"\"\n    # Bit masks\n    SET_BIT_5 = 1 << 5   # 32\n    CLEAR_BIT_2_MASK = ~(1 << 2)  # ...11111011 in two's-complement\n\n    # Set bit 5 then clear bit 2\n    return (state | SET_BIT_5) & CLEAR_BIT_2_MASK", "reference_tests": [{"type": "basic", "inputs": [0], "output": 32}, {"type": "basic", "inputs": [4], "output": 32}, {"type": "basic", "inputs": [36], "output": 32}, {"type": "edge_case", "inputs": [255], "output": 251}, {"type": "edge_case", "inputs": [-1], "output": -5}], "sample_type": "code_synthetic", "shards": [{"shard_id": 3, "shard": "Also flip bit two off making that position zero"}, {"shard_id": 1, "shard": "Task modify a given integer by manipulating specific bits inside it"}, {"shard_id": 4, "shard": "Output the new integer keeping every other bit unchanged"}, {"shard_id": 2, "shard": "Under zero based indexing ensure bit five holds value one"}], "task": "code", "task_id": "sharded-synthetic-code-92", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.25, "sharded-all": {"t-gpt-4.1": [0, 0, 0, 0, 0, 0, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "energy_meter_flag_set"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"0\", \"output\": \"32\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"4\", \"output\": \"32\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"36\", \"output\": \"32\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"255\", \"output\": \"251\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"-1\", \"output\": \"-5\", \"testtype\": \"functional\"}]"}, {"problem_id": 65, "category": "list_processing", "name": "segment_playlist", "domain": "music", "description": "Split playlist durations into contiguous segments whose total not exceed limit L. Return list of segment lengths.", "verified": true, "reference_solution": "def segment_playlist(durations, L):\n    \"\"\"Split the given playlist into contiguous segments whose total duration\n    does not exceed L. Return a list where each element is the number of tracks\n    in the corresponding segment (i.e., the segment length in items).\"\"\"\n    segments = []\n    current_sum = 0\n    current_count = 0\n\n    for d in durations:\n        # If adding this track would exceed the limit, close current segment\n        if current_count and current_sum + d > L:\n            segments.append(current_count)\n            current_sum = 0\n            current_count = 0\n        # Start / continue current segment\n        current_sum += d\n        current_count += 1\n    # Append the last segment if present\n    if current_count:\n        segments.append(current_count)\n\n    return segments", "reference_tests": [{"type": "basic", "inputs": [[4, 2, 3, 5], 6], "output": [2, 1, 1]}, {"type": "basic", "inputs": [[1, 2, 3], 3], "output": [2, 1]}, {"type": "edge_case", "inputs": [[], 10], "output": []}, {"type": "edge_case", "inputs": [[5, 5, 5], 20], "output": [3]}, {"type": "edge_case", "inputs": [[7], 10], "output": [1]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 1, "shard": "Goal split playlist into consecutive groups where each group time stays within limit"}, {"shard_id": 4, "shard": "Output list showing counts of tracks in each group in their original order"}, {"shard_id": 2, "shard": "Input a list of durations and a maximum allowed sum number"}, {"shard_id": 3, "shard": "Process sequentially starting new group whenever adding next duration breaks the limit"}], "task": "code", "task_id": "sharded-synthetic-code-65", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.25, "sharded-all": {"t-gpt-4.1": [1, 0, 1, 0, 0, 0, 0, 0]}}, "acceptable": 1, "metadata": {"func_name": "segment_playlist"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[4, 2, 3, 5]\\n6\", \"output\": \"[2, 1, 1]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[1, 2, 3]\\n3\", \"output\": \"[2, 1]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\\n10\", \"output\": \"[]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[5, 5, 5]\\n20\", \"output\": \"[3]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[7]\\n10\", \"output\": \"[1]\", \"testtype\": \"functional\"}]"}, {"problem_id": 6, "category": "combinatorics", "name": "nurse_shift_reorderings", "domain": "healthcare", "description": "Return number of unique circular arrangements for n nurses around a desk where rotations are considered identical. Expect n between 1 and 15 inclusive.", "verified": true, "reference_solution": "def nurse_shift_reorderings(n):\n    \"\"\"Return the number of unique circular arrangements for n nurses.\n    In a circular arrangement, rotations are considered identical, so the count\n    is (n-1)! for n >= 1. The function assumes 1 <= n <= 15.\n    \"\"\"\n    if not isinstance(n, int):\n        raise TypeError(\"Input must be an integer\")\n    if n < 1 or n > 15:\n        raise ValueError(\"n must be between 1 and 15 inclusive\")\n    # (n-1)! calculation\n    result = 1\n    for i in range(2, n):  # multiply from 2 to n-1\n        result *= i\n    return result\n", "reference_tests": [{"type": "basic", "inputs": [3], "output": 2}, {"type": "basic", "inputs": [5], "output": 24}, {"type": "edge_case", "inputs": [1], "output": 1}, {"type": "edge_case", "inputs": [2], "output": 1}, {"type": "edge_case", "inputs": [15], "output": 87178291200}], "sample_type": "code_synthetic", "shards": [{"shard_id": 1, "shard": "Arrange nurses round a desk count distinct seat orders"}, {"shard_id": 4, "shard": "Sample three nurses yields two seatings follow that pattern for others"}, {"shard_id": 2, "shard": "Rotate the circle any amount and it still counts as same order"}, {"shard_id": 3, "shard": "Input is one integer n between one and fifteen output is an integer"}], "task": "code", "task_id": "sharded-synthetic-code-6", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "nurse_shift_reorderings"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"3\", \"output\": \"2\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"5\", \"output\": \"24\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"1\", \"output\": \"1\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"2\", \"output\": \"1\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"15\", \"output\": \"87178291200\", \"testtype\": \"functional\"}]"}, {"problem_id": 85, "category": "list_processing", "name": "merge_route_stops", "domain": "transport", "description": "Merge two sorted stop name lists into one sorted list without duplicates, preserving original case from first appearance.", "verified": true, "reference_solution": "def merge_route_stops(route_a, route_b):\n    \"\"\"Merge two alphabetically sorted lists of stop names, returning a single\n    sorted list that contains each stop only once (duplicates are detected\n    case-insensitively).  The original capitalisation of the first occurrence\n    of every stop is preserved.\n    \"\"\"\n\n    i = j = 0\n    result = []\n    seen_lower = set()  # store lower-cased versions we've already added\n\n    # Helper that tries to append a stop if it hasn't been added yet\n    def try_add(stop):\n        key = stop.lower()\n        if key not in seen_lower:\n            seen_lower.add(key)\n            result.append(stop)\n\n    # Merge while both lists still have elements\n    while i < len(route_a) and j < len(route_b):\n        a, b = route_a[i], route_b[j]\n        a_lower, b_lower = a.lower(), b.lower()\n\n        if a_lower == b_lower:\n            # Same stop (ignoring case) appears in both lists\n            try_add(a)  # keep capitalisation from first appearance (route_a)\n            i += 1\n            j += 1\n        elif a_lower < b_lower:\n            try_add(a)\n            i += 1\n        else:  # b_lower < a_lower\n            try_add(b)\n            j += 1\n\n    # Append any leftovers from either list\n    while i < len(route_a):\n        try_add(route_a[i])\n        i += 1\n    while j < len(route_b):\n        try_add(route_b[j])\n        j += 1\n\n    return result\n", "reference_tests": [{"type": "basic", "inputs": [["Alpha", "Bravo", "Charlie"], ["Bravo", "Delta"]], "output": ["Alpha", "Bravo", "Charlie", "Delta"]}, {"type": "basic", "inputs": [["Central", "Main"], ["central", "Park", "main"]], "output": ["Central", "Main", "Park"]}, {"type": "edge_case", "inputs": [[], ["A", "B"]], "output": ["A", "B"]}, {"type": "edge_case", "inputs": [[], []], "output": []}, {"type": "edge_case", "inputs": [["Avenue", "Street"], ["Boulevard", "street", "Terrace"]], "output": ["Avenue", "Boulevard", "Street", "Terrace"]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 3, "shard": "Treat duplicates case insensitively so Bravo and bravo considered same stop"}, {"shard_id": 2, "shard": "Keep capitalization from the first appearance when adding a stop to output"}, {"shard_id": 4, "shard": "Input two sorted string lists output one sorted list of unique stop names"}, {"shard_id": 1, "shard": "Merge two alphabetic stop name lists into one tidy list without repeats"}], "task": "code", "task_id": "sharded-synthetic-code-85", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.875, "sharded-all": {"t-gpt-4.1": [1, 0, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "merge_route_stops"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[\\\"Alpha\\\", \\\"Bravo\\\", \\\"Charlie\\\"]\\n[\\\"Bravo\\\", \\\"Delta\\\"]\", \"output\": \"[\\\"Alpha\\\", \\\"Bravo\\\", \\\"Charlie\\\", \\\"Delta\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[\\\"Central\\\", \\\"Main\\\"]\\n[\\\"central\\\", \\\"Park\\\", \\\"main\\\"]\", \"output\": \"[\\\"Central\\\", \\\"Main\\\", \\\"Park\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\\n[\\\"A\\\", \\\"B\\\"]\", \"output\": \"[\\\"A\\\", \\\"B\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\\n[]\", \"output\": \"[]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"Avenue\\\", \\\"Street\\\"]\\n[\\\"Boulevard\\\", \\\"street\\\", \\\"Terrace\\\"]\", \"output\": \"[\\\"Avenue\\\", \\\"Boulevard\\\", \\\"Street\\\", \\\"Terrace\\\"]\", \"testtype\": \"functional\"}]"}, {"problem_id": 73, "category": "simulation", "name": "simulate_temperature_control", "domain": "IoT", "description": "Given target temp and list of room readings, simulate thermostat toggling: heater on when reading <target-0.5, off when >target+0.5. Return list of states 'ON'/'OFF'.", "verified": true, "reference_solution": "def simulate_temperature_control(target_temperature, readings):\n    \"\"\"Simulate a thermostat with simple hysteresis control.\n\n    The heater is switched ON when the temperature reading drops strictly below\n    (target - 0.5) and switched OFF when the reading rises strictly above\n    (target + 0.5). When the reading lies within the buffer zone\n    [target - 0.5, target + 0.5], the current state is maintained.\n\n    Parameters\n    ----------\n    target_temperature : float\n        Desired target temperature.\n    readings : list[float]\n        Chronological list of temperature readings.\n\n    Returns\n    -------\n    list[str]\n        List containing the heater state (\"ON\" or \"OFF\") after each reading.\n    \"\"\"\n\n    lower_threshold = target_temperature - 0.5\n    upper_threshold = target_temperature + 0.5\n\n    state = \"OFF\"  # Initial state\n    result = []\n\n    for temp in readings:\n        if temp < lower_threshold:\n            state = \"ON\"\n        elif temp > upper_threshold:\n            state = \"OFF\"\n        # else: retain previous state\n        result.append(state)\n\n    return result", "reference_tests": [{"type": "basic", "inputs": [20, [19, 19.5, 20, 21]], "output": ["ON", "ON", "ON", "OFF"]}, {"type": "basic", "inputs": [22, [23, 22.6, 22, 21.4]], "output": ["OFF", "OFF", "OFF", "ON"]}, {"type": "edge_case", "inputs": [18.5, []], "output": []}, {"type": "edge_case", "inputs": [25, [24, 24.4, 24.49, 24.51, 24.9, 25.6, 25.4, 25]], "output": ["ON", "ON", "ON", "ON", "ON", "OFF", "OFF", "OFF"]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 3, "shard": "Switch heater to ON whenever reading drops below target minus zero point five"}, {"shard_id": 2, "shard": "You get a target number and a list of room temperatures"}, {"shard_id": 1, "shard": "Make a simple thermostat history from temperature readings"}, {"shard_id": 4, "shard": "Switch to OFF when it rises above target plus zero point five else keep state"}], "task": "code", "task_id": "sharded-synthetic-code-73", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.125, "sharded-all": {"t-gpt-4.1": [0, 0, 0, 0, 0, 1, 0, 0]}}, "acceptable": 1, "metadata": {"func_name": "simulate_temperature_control"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"20\\n[19, 19.5, 20, 21]\", \"output\": \"[\\\"ON\\\", \\\"ON\\\", \\\"ON\\\", \\\"OFF\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"22\\n[23, 22.6, 22, 21.4]\", \"output\": \"[\\\"OFF\\\", \\\"OFF\\\", \\\"OFF\\\", \\\"ON\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"18.5\\n[]\", \"output\": \"[]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"25\\n[24, 24.4, 24.49, 24.51, 24.9, 25.6, 25.4, 25]\", \"output\": \"[\\\"ON\\\", \\\"ON\\\", \\\"ON\\\", \\\"ON\\\", \\\"ON\\\", \\\"OFF\\\", \\\"OFF\\\", \\\"OFF\\\"]\", \"testtype\": \"functional\"}]"}, {"problem_id": 33, "category": "simulation", "name": "population_decay", "domain": "science", "description": "Simulate population P with decay rate r% per year for n years, rounding to nearest integer each year. Return list including initial population.", "verified": true, "reference_solution": "def population_decay(P: int, r: float, n: int):\n    \"\"\"Simulate population decay.\n\n    Parameters:\n    P (int): initial population\n    r (float): decay rate in percent per year\n    n (int): number of years to simulate\n\n    Returns:\n    list: populations from year 0 through year n (inclusive), each rounded to the nearest integer after each year's decay.\n    \"\"\"\n    # Validate inputs minimally\n    if n < 0:\n        raise ValueError(\"Number of years 'n' must be non-negative\")\n\n    populations = [int(P)]  # ensure starting value is an integer\n    current = P\n    for _ in range(n):\n        current = round(current * (1 - r / 100.0))\n        populations.append(int(current))\n    return populations", "reference_tests": [{"type": "basic", "inputs": [1000, 10, 3], "output": [1000, 900, 810, 729]}, {"type": "basic", "inputs": [500, 20, 2], "output": [500, 400, 320]}, {"type": "edge_case", "inputs": [123, 5, 0], "output": [123]}, {"type": "edge_case", "inputs": [1000, 0, 4], "output": [1000, 1000, 1000, 1000, 1000]}, {"type": "edge_case", "inputs": [5, 50, 1], "output": [5, 2]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 3, "shard": "Each year multiply by one minus r percent round nearest whole"}, {"shard_id": 2, "shard": "Input start number P rate r percent years n"}, {"shard_id": 1, "shard": "Model yearly shrinking population and list each years count"}, {"shard_id": 4, "shard": "Return list from year zero through n for example 1000 10 3 gives 1000 900 810 729"}], "task": "code", "task_id": "sharded-synthetic-code-33", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.875, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 0, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "population_decay"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"1000\\n10\\n3\", \"output\": \"[1000, 900, 810, 729]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"500\\n20\\n2\", \"output\": \"[500, 400, 320]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"123\\n5\\n0\", \"output\": \"[123]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"1000\\n0\\n4\", \"output\": \"[1000, 1000, 1000, 1000, 1000]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"5\\n50\\n1\", \"output\": \"[5, 2]\", \"testtype\": \"functional\"}]"}, {"problem_id": 95, "category": "counting", "name": "count_peak_hours", "domain": "energy", "description": "Given hourly usage list and threshold, count hours where usage exceeds threshold and is greater than both neighbors.", "verified": true, "reference_solution": "def count_peak_hours(usage, threshold):\n    \"\"\"Count the number of \"peak\" hours.\n\n    A peak hour i satisfies:\n        * i is not the first or last index (has two neighbors)\n        * usage[i] > threshold\n        * usage[i] is greater than both immediate neighbors\n    \"\"\"\n    if not usage or len(usage) < 3:\n        return 0\n\n    count = 0\n    # iterate from 1 to len-2 (exclude first and last)\n    for i in range(1, len(usage) - 1):\n        if usage[i] > threshold and usage[i] > usage[i - 1] and usage[i] > usage[i + 1]:\n            count += 1\n    return count", "reference_tests": [{"type": "basic", "inputs": [[1, 3, 2, 4, 1], 2], "output": 2}, {"type": "basic", "inputs": [[0, 5, 0, 6, 1, 7, 0], 4], "output": 3}, {"type": "edge_case", "inputs": [[5, 4, 3, 2, 1], 2], "output": 0}, {"type": "edge_case", "inputs": [[10, 9, 10, 9, 10], 10], "output": 0}, {"type": "edge_case", "inputs": [[5, 6], 4], "output": 0}], "sample_type": "code_synthetic", "shards": [{"shard_id": 1, "shard": "Count peak usage hours over a set threshold"}, {"shard_id": 3, "shard": "A peak hour must beat both neighboring hours"}, {"shard_id": 2, "shard": "Input one list of hourly numbers and one threshold number"}, {"shard_id": 4, "shard": "Skip first and last positions and return total count"}], "task": "code", "task_id": "sharded-synthetic-code-95", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "count_peak_hours"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[1, 3, 2, 4, 1]\\n2\", \"output\": \"2\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[0, 5, 0, 6, 1, 7, 0]\\n4\", \"output\": \"3\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[5, 4, 3, 2, 1]\\n2\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[10, 9, 10, 9, 10]\\n10\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[5, 6]\\n4\", \"output\": \"0\", \"testtype\": \"functional\"}]"}, {"problem_id": 47, "category": "date_time", "name": "closest_palindrome_date", "domain": "linguistics", "description": "For given YYYY-MM-DD, find nearest future date whose digits read same forward and backward when written YYYYMMDD.", "verified": true, "reference_solution": "def closest_palindrome_date(date_str):\n    \"\"\"Return the closest future date (strictly after the given date) such that\n    the concatenation YYYYMMDD is a palindrome.\n    \n    Args:\n        date_str (str): Date in the format 'YYYY-MM-DD'.\n\n    Returns:\n        str: The next palindrome date in 'YYYY-MM-DD' format.\n    \"\"\"\n    import datetime\n\n    # Parse the incoming date string\n    try:\n        current_date = datetime.datetime.strptime(date_str, \"%Y-%m-%d\").date()\n    except ValueError:\n        raise ValueError(\"Input must be a valid date in YYYY-MM-DD format\")\n\n    # Helper to test palindromicity of a date\n    def is_palindrome(d: datetime.date) -> bool:\n        s = d.strftime(\"%Y%m%d\")\n        return s == s[::-1]\n\n    one_day = datetime.timedelta(days=1)\n    max_date = datetime.date(9999, 12, 31)\n    next_date = current_date + one_day  # must be strictly in the future\n\n    while next_date <= max_date:\n        if is_palindrome(next_date):\n            return next_date.strftime(\"%Y-%m-%d\")\n        next_date += one_day\n\n    # If we exhaust the supported range, signal the problem.\n    raise ValueError(\"No palindrome date exists in supported range after the given date\")\n", "reference_tests": [{"type": "basic", "inputs": ["2021-12-01"], "output": "2021-12-02"}, {"type": "basic", "inputs": ["2021-12-02"], "output": "2030-03-02"}, {"type": "edge_case", "inputs": ["1999-12-31"], "output": "2001-10-02"}, {"type": "edge_case", "inputs": ["2011-11-11"], "output": "2020-02-02"}, {"type": "edge_case", "inputs": ["2001-10-01"], "output": "2001-10-02"}], "sample_type": "code_synthetic", "shards": [{"shard_id": 2, "shard": "Input arrives as YYYY dash MM dash DD like 2021 dash 12 dash 01"}, {"shard_id": 3, "shard": "Drop the dashes join to YYYYMMDD then test if it mirrors perfectly"}, {"shard_id": 1, "shard": "Find the next calendar day whose digits read the same backward"}, {"shard_id": 4, "shard": "Return the first such day strictly later than the one supplied"}], "task": "code", "task_id": "sharded-synthetic-code-47", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 0.75, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 0, 1, 0, 1, 1, 1]}, "sharded-avg": 0.0, "sharded-all": {"t-gpt-4.1": [0, 0, 0, 0, 0, 0, 0, 0]}}, "acceptable": 1, "metadata": {"func_name": "closest_palindrome_date"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"\\\"2021-12-01\\\"\", \"output\": \"\\\"2021-12-02\\\"\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"\\\"2021-12-02\\\"\", \"output\": \"\\\"2030-03-02\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"1999-12-31\\\"\", \"output\": \"\\\"2001-10-02\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"2011-11-11\\\"\", \"output\": \"\\\"2020-02-02\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"2001-10-01\\\"\", \"output\": \"\\\"2001-10-02\\\"\", \"testtype\": \"functional\"}]"}, {"problem_id": 13, "category": "simulation", "name": "simulate_retweet_chain", "domain": "social_media", "description": "Given seed tweet ID and list of pairs (retweeter, parent), trace chain until original tweet. Return list of IDs from original to latest. Assume valid acyclic chain.", "verified": true, "reference_solution": "def simulate_retweet_chain(seed_id, retweet_pairs):\n    \"\"\"Return the list of tweet IDs from the original tweet to the given seed tweet.\n\n    Parameters\n    ----------\n    seed_id : int or str\n        The id of the most recent (seed) tweet/retweet.\n    retweet_pairs : list[tuple|list]\n        Each pair (retweeter, parent) means *retweeter* is a retweet of *parent*.\n\n    Returns\n    -------\n    list\n        Tweet IDs starting with the original tweet id and ending with *seed_id*.\n    \"\"\"\n    # Build a mapping: child -> parent\n    parent_of = {}\n    for child, parent in retweet_pairs:\n        parent_of[child] = parent\n\n    chain = [seed_id]\n    current = seed_id\n    # Walk up until we find the original tweet (which has no parent recorded)\n    while current in parent_of:\n        current = parent_of[current]\n        chain.append(current)\n\n    # We walked from latest to original; reverse to original -> latest\n    return chain[::-1]\n", "reference_tests": [{"type": "basic", "inputs": [3, [[3, 2], [2, 1]]], "output": [1, 2, 3]}, {"type": "edge_case", "inputs": [10, []], "output": [10]}, {"type": "basic", "inputs": [5, [[5, 4], [3, 2], [4, 3]]], "output": [2, 3, 4, 5]}, {"type": "edge_case", "inputs": ["d", [["b", "a"], ["c", "b"], ["d", "c"]]], "output": ["a", "b", "c", "d"]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 3, "shard": "No loops exist so you can walk parent links back safely"}, {"shard_id": 4, "shard": "Return ids ordered earliest original first latest seed last"}, {"shard_id": 2, "shard": "Input has the seed id and pairs showing who retweeted whom"}, {"shard_id": 1, "shard": "Trace tweet history from original source up to provided newest tweet id"}], "task": "code", "task_id": "sharded-synthetic-code-13", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 0.875, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 0, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.5, "sharded-all": {"t-gpt-4.1": [0, 1, 1, 0, 0, 0, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "simulate_retweet_chain"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"3\\n[[3, 2], [2, 1]]\", \"output\": \"[1, 2, 3]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"10\\n[]\", \"output\": \"[10]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"5\\n[[5, 4], [3, 2], [4, 3]]\", \"output\": \"[2, 3, 4, 5]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"d\\\"\\n[[\\\"b\\\", \\\"a\\\"], [\\\"c\\\", \\\"b\\\"], [\\\"d\\\", \\\"c\\\"]]\", \"output\": \"[\\\"a\\\", \\\"b\\\", \\\"c\\\", \\\"d\\\"]\", \"testtype\": \"functional\"}]"}, {"problem_id": 11, "category": "set_operations", "name": "mutual_followers_count", "domain": "social_media", "description": "Given two lists of user IDs for followers of accounts A and B, return count of users who follow both, ignoring duplicate IDs within each list.", "verified": true, "reference_solution": "def mutual_followers_count(followers_a, followers_b):\n    \"\"\"Return the number of unique user IDs that appear in both followers_a and followers_b.\n    Duplicate IDs inside each input list are ignored.\n    \"\"\"\n    # Convert both lists to sets to eliminate duplicates and enable fast intersection\n    set_a = set(followers_a)\n    set_b = set(followers_b)\n\n    # Intersection gives users following both accounts\n    mutual = set_a & set_b\n\n    # Return the count of mutual followers\n    return len(mutual)\n", "reference_tests": [{"type": "basic", "inputs": [[1, 2, 3, 4], [3, 4, 5]], "output": 2}, {"type": "basic", "inputs": [[10, 20, 20, 30], [20, 40, 10, 10]], "output": 2}, {"type": "edge_case", "inputs": [[], [1, 2, 3]], "output": 0}, {"type": "edge_case", "inputs": [[1, 1, 1], [1, 1]], "output": 1}, {"type": "edge_case", "inputs": [[], []], "output": 0}, {"type": "basic", "inputs": [[100, 200, 300], [400, 500, 600]], "output": 0}], "sample_type": "code_synthetic", "shards": [{"shard_id": 4, "shard": "Return how many shared ids count zero allowed"}, {"shard_id": 2, "shard": "Input two lists of user ids maybe with repeats"}, {"shard_id": 3, "shard": "Treat each list as unique set then find shared ids"}, {"shard_id": 1, "shard": "Need number of users following both accounts duplicates irrelevant"}], "task": "code", "task_id": "sharded-synthetic-code-11", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "mutual_followers_count"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[1, 2, 3, 4]\\n[3, 4, 5]\", \"output\": \"2\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[10, 20, 20, 30]\\n[20, 40, 10, 10]\", \"output\": \"2\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\\n[1, 2, 3]\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[1, 1, 1]\\n[1, 1]\", \"output\": \"1\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\\n[]\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[100, 200, 300]\\n[400, 500, 600]\", \"output\": \"0\", \"testtype\": \"functional\"}]"}, {"problem_id": 80, "category": "filtering", "name": "filter_ip_range", "domain": "cybersecurity", "description": "Return IPs not within any CIDR ranges in blacklist list. IPv4 only, no subnet > /8.", "verified": true, "reference_solution": "def filter_ip_range(ips, blacklist):\n    \"\"\"Return list of IP strings from `ips` that are NOT contained in any CIDR\n    network present in `blacklist`.\n\n    Args:\n        ips (list[str]): List of IPv4 address strings.\n        blacklist (list[str]): List of IPv4 CIDR blocks (e.g., \"192.168.0.0/16\").\n\n    Returns:\n        list[str]: Filtered list with the same order as `ips`, excluding those\n                    addresses that fall inside any blacklisted network.\n    \"\"\"\n    import ipaddress\n\n    # Convert blacklist entries to IPv4Network objects once for efficiency\n    networks = []\n    for cidr in blacklist:\n        try:\n            networks.append(ipaddress.IPv4Network(cidr, strict=False))\n        except ValueError:\n            # Skip malformed CIDR blocks (problem statement doesn't specify, but safer)\n            continue\n\n    # Prepare result while preserving order\n    result = []\n    for ip_str in ips:\n        try:\n            ip_obj = ipaddress.IPv4Address(ip_str)\n        except ValueError:\n            # Ignore malformed IP addresses (problem statement doesn't specify)\n            continue\n        # Check membership in any blacklist network\n        if not any(ip_obj in net for net in networks):\n            result.append(ip_str)\n    return result", "reference_tests": [{"type": "basic", "inputs": [["192.168.1.1", "10.0.0.5", "172.16.0.1"], ["192.168.0.0/16"]], "output": ["10.0.0.5", "172.16.0.1"]}, {"type": "basic", "inputs": [["8.8.8.8", "1.1.1.1"], []], "output": ["8.8.8.8", "1.1.1.1"]}, {"type": "edge_case", "inputs": [[], ["10.0.0.0/8"]], "output": []}, {"type": "edge_case", "inputs": [["10.0.1.1", "192.0.2.1"], ["10.0.0.0/8", "10.0.0.0/16"]], "output": ["192.0.2.1"]}, {"type": "edge_case", "inputs": [["203.0.113.5", "203.0.113.6"], ["203.0.113.5/32"]], "output": ["203.0.113.6"]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 1, "shard": "Remove addresses inside any blacklisted CIDR range"}, {"shard_id": 2, "shard": "Input two lists ipv4 strings and cidr blocks maximal mask eight"}, {"shard_id": 4, "shard": "Block 192.168.0.0/16 lets 10.0.0.5 through"}, {"shard_id": 3, "shard": "Return addresses not contained keep original order duplicates preserved"}], "task": "code", "task_id": "sharded-synthetic-code-80", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 0.75, "concat-all": {"t-gpt-4.1": [1, 1, 1, 0, 1, 0, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "filter_ip_range"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[\\\"192.168.1.1\\\", \\\"10.0.0.5\\\", \\\"172.16.0.1\\\"]\\n[\\\"192.168.0.0/16\\\"]\", \"output\": \"[\\\"10.0.0.5\\\", \\\"172.16.0.1\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[\\\"8.8.8.8\\\", \\\"1.1.1.1\\\"]\\n[]\", \"output\": \"[\\\"8.8.8.8\\\", \\\"1.1.1.1\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\\n[\\\"10.0.0.0/8\\\"]\", \"output\": \"[]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"10.0.1.1\\\", \\\"192.0.2.1\\\"]\\n[\\\"10.0.0.0/8\\\", \\\"10.0.0.0/16\\\"]\", \"output\": \"[\\\"192.0.2.1\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"203.0.113.5\\\", \\\"203.0.113.6\\\"]\\n[\\\"203.0.113.5/32\\\"]\", \"output\": \"[\\\"203.0.113.6\\\"]\", \"testtype\": \"functional\"}]"}, {"problem_id": 35, "category": "counting", "name": "count_prime_measurements", "domain": "science", "description": "Count how many measurement integers are prime. Input size \u226410 000.", "verified": true, "reference_solution": "def count_prime_measurements(measurements):\n    \"\"\"Return the count of prime numbers inside the iterable *measurements*.\n\n    A prime number is an integer greater than 1 that has no positive divisors other\n    than 1 and itself. Negative numbers, 0 and 1 are not considered prime.\n    \"\"\"\n    def is_prime(n: int) -> bool:\n        if n <= 1:\n            return False\n        if n <= 3:\n            return True  # 2 and 3 are prime\n        if n % 2 == 0 or n % 3 == 0:\n            return False\n        # Check from 5 to sqrt(n) skipping even numbers and multiples of 3.\n        i = 5\n        step = 2  # alternates 2, 4 (i.e., 6k \u00b1 1 checks)\n        while i * i <= n:\n            if n % i == 0:\n                return False\n            i += step\n            step = 6 - step  # toggles between adding 2 and 4\n        return True\n\n    return sum(1 for value in measurements if is_prime(value))", "reference_tests": [{"type": "basic", "inputs": [[2, 3, 4, 5, 6, 7]], "output": 4}, {"type": "basic", "inputs": [[10, 11, 12, 13, 14, 15]], "output": 2}, {"type": "edge_case", "inputs": [[-3, -2, 0, 1]], "output": 0}, {"type": "edge_case", "inputs": [[]], "output": 0}, {"type": "edge_case", "inputs": [[99991, 99989, 100000]], "output": 2}], "sample_type": "code_synthetic", "shards": [{"shard_id": 4, "shard": "Zero one and negatives never qualify as prime here"}, {"shard_id": 1, "shard": "Count prime valued entries in a provided measurement list"}, {"shard_id": 3, "shard": "Output one integer that reports how many are prime"}, {"shard_id": 2, "shard": "Input is at most ten thousand whole numbers"}], "task": "code", "task_id": "sharded-synthetic-code-35", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "count_prime_measurements"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[2, 3, 4, 5, 6, 7]\", \"output\": \"4\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[10, 11, 12, 13, 14, 15]\", \"output\": \"2\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[-3, -2, 0, 1]\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[99991, 99989, 100000]\", \"output\": \"2\", \"testtype\": \"functional\"}]"}, {"problem_id": 49, "category": "searching", "name": "find_word_variant", "domain": "linguistics", "description": "Given sorted list of dictionary words, binary search for word ignoring accents (provided as separate mapping). Return index or -1.", "verified": true, "reference_solution": "def find_word_variant(words, target, mapping):\n    \"\"\"Binary-search `words` (sorted under accent-insensitive order) for a word\n    that matches `target` once every character is normalised with *mapping*.\n\n    Parameters\n    ----------\n    words : list[str]\n        Sorted list of dictionary words (accented characters allowed).\n    target : str\n        Word being searched for (typically without accents).\n    mapping : dict[str, str]\n        Maps accented characters to their unaccented counterparts.\n\n    Returns\n    -------\n    int\n        Index of a matching word in *words* or -1 when no match exists.\n    \"\"\"\n\n    # Helper that removes accents using the provided mapping.\n    def _normalize(s: str) -> str:\n        # Turn every char into its mapped replacement (or itself).\n        return ''.join(mapping.get(ch, ch) for ch in s).lower()\n\n    target_norm = _normalize(target)\n    lo, hi = 0, len(words) - 1\n\n    while lo <= hi:\n        mid = (lo + hi) // 2\n        mid_norm = _normalize(words[mid])\n\n        if mid_norm == target_norm:\n            return mid  # found exact accent-insensitive match\n        if mid_norm < target_norm:\n            lo = mid + 1\n        else:\n            hi = mid - 1\n    return -1\n", "reference_tests": [{"type": "basic", "inputs": [["caf\u00e9", "jalape\u00f1o", "pi\u00f1ata", "r\u00e9sum\u00e9"], "resume", {"\u00e9": "e", "\u00f1": "n", "\u00ed": "i", "\u00e1": "a", "\u00f3": "o"}], "output": 3}, {"type": "basic", "inputs": [["a\u00f1o", "\u00e1rbol", "ni\u00f1o"], "arbol", {"\u00f1": "n", "\u00e1": "a"}], "output": 1}, {"type": "edge_case", "inputs": [["caf\u00e9", "jalape\u00f1o", "pi\u00f1ata", "r\u00e9sum\u00e9"], "cafeine", {"\u00e9": "e", "\u00f1": "n", "\u00ed": "i", "\u00e1": "a", "\u00f3": "o"}], "output": -1}, {"type": "edge_case", "inputs": [[], "anything", {"\u00e9": "e"}], "output": -1}, {"type": "basic", "inputs": [["\u00e9l", "ella", "ellos"], "el", {"\u00e9": "e"}], "output": 0}], "sample_type": "code_synthetic", "shards": [{"shard_id": 3, "shard": "Leverage binary search since list already sorted under normalized order"}, {"shard_id": 2, "shard": "Convert letters via given accent map before equality check"}, {"shard_id": 4, "shard": "Return index if match exists otherwise minus one"}, {"shard_id": 1, "shard": "Search alphabetized word list while ignoring diacritical marks"}], "task": "code", "task_id": "sharded-synthetic-code-49", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 0.875, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 0, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "find_word_variant"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[\\\"caf\\\\u00e9\\\", \\\"jalape\\\\u00f1o\\\", \\\"pi\\\\u00f1ata\\\", \\\"r\\\\u00e9sum\\\\u00e9\\\"]\\n\\\"resume\\\"\\n{\\\"\\\\u00e9\\\": \\\"e\\\", \\\"\\\\u00f1\\\": \\\"n\\\", \\\"\\\\u00ed\\\": \\\"i\\\", \\\"\\\\u00e1\\\": \\\"a\\\", \\\"\\\\u00f3\\\": \\\"o\\\"}\", \"output\": \"3\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[\\\"a\\\\u00f1o\\\", \\\"\\\\u00e1rbol\\\", \\\"ni\\\\u00f1o\\\"]\\n\\\"arbol\\\"\\n{\\\"\\\\u00f1\\\": \\\"n\\\", \\\"\\\\u00e1\\\": \\\"a\\\"}\", \"output\": \"1\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"caf\\\\u00e9\\\", \\\"jalape\\\\u00f1o\\\", \\\"pi\\\\u00f1ata\\\", \\\"r\\\\u00e9sum\\\\u00e9\\\"]\\n\\\"cafeine\\\"\\n{\\\"\\\\u00e9\\\": \\\"e\\\", \\\"\\\\u00f1\\\": \\\"n\\\", \\\"\\\\u00ed\\\": \\\"i\\\", \\\"\\\\u00e1\\\": \\\"a\\\", \\\"\\\\u00f3\\\": \\\"o\\\"}\", \"output\": \"-1\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\\n\\\"anything\\\"\\n{\\\"\\\\u00e9\\\": \\\"e\\\"}\", \"output\": \"-1\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[\\\"\\\\u00e9l\\\", \\\"ella\\\", \\\"ellos\\\"]\\n\\\"el\\\"\\n{\\\"\\\\u00e9\\\": \\\"e\\\"}\", \"output\": \"0\", \"testtype\": \"functional\"}]"}, {"problem_id": 27, "category": "date_time", "name": "daily_login_streaks", "domain": "gaming", "description": "Given sorted list of login date strings, return longest consecutive streak length. Dates are in YYYY-MM-DD format with no duplicates.", "verified": true, "reference_solution": "from datetime import datetime, timedelta\n\ndef daily_login_streaks(dates):\n    \"\"\"Return the length of the longest consecutive login streak.\n    dates: a sorted list of unique date strings in 'YYYY-MM-DD' format.\n    \"\"\"\n    if not dates:\n        return 0\n\n    # Convert strings to date objects for easy arithmetic\n    date_objs = [datetime.strptime(d, \"%Y-%m-%d\").date() for d in dates]\n\n    max_streak = 1\n    current_streak = 1\n\n    for prev, curr in zip(date_objs, date_objs[1:]):\n        if curr - prev == timedelta(days=1):\n            current_streak += 1\n        else:\n            current_streak = 1\n        if current_streak > max_streak:\n            max_streak = current_streak\n\n    return max_streak\n", "reference_tests": [{"type": "basic", "inputs": [["2023-01-01", "2023-01-02", "2023-01-05", "2023-01-06", "2023-01-07"]], "output": 3}, {"type": "edge_case", "inputs": [[]], "output": 0}, {"type": "basic", "inputs": [["2023-03-10", "2023-03-11", "2023-03-12", "2023-03-13", "2023-03-14", "2023-03-15"]], "output": 6}, {"type": "edge_case", "inputs": [["2023-01-01", "2023-01-03", "2023-01-05"]], "output": 1}, {"type": "edge_case", "inputs": [["2020-02-28", "2020-02-29", "2020-03-01"]], "output": 3}], "sample_type": "code_synthetic", "shards": [{"shard_id": 2, "shard": "Input is sorted list of unique date strings like 2023-03-14"}, {"shard_id": 1, "shard": "Find the maximum consecutive login streak length from provided dates"}, {"shard_id": 4, "shard": "Example list 2023-01-01 2023-01-02 2023-01-05 2023-01-06 2023-01-07 yields 3"}, {"shard_id": 3, "shard": "Return integer length of longest run of back to back days"}], "task": "code", "task_id": "sharded-synthetic-code-27", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.875, "sharded-all": {"t-gpt-4.1": [1, 1, 0, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "daily_login_streaks"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[\\\"2023-01-01\\\", \\\"2023-01-02\\\", \\\"2023-01-05\\\", \\\"2023-01-06\\\", \\\"2023-01-07\\\"]\", \"output\": \"3\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[\\\"2023-03-10\\\", \\\"2023-03-11\\\", \\\"2023-03-12\\\", \\\"2023-03-13\\\", \\\"2023-03-14\\\", \\\"2023-03-15\\\"]\", \"output\": \"6\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"2023-01-01\\\", \\\"2023-01-03\\\", \\\"2023-01-05\\\"]\", \"output\": \"1\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"2020-02-28\\\", \\\"2020-02-29\\\", \\\"2020-03-01\\\"]\", \"output\": \"3\", \"testtype\": \"functional\"}]"}, {"problem_id": 34, "category": "recursion", "name": "chemical_chain_rewrite", "domain": "science", "description": "Recursively replace every occurrence of pattern 'AB' with 'BA' in a molecule string until no more replacements possible; return final string.", "verified": true, "reference_solution": "def chemical_chain_rewrite(molecule: str) -> str:\n    \"\"\"\n    Recursively replace every occurrence of the pattern 'AB' with 'BA' in the\n    provided molecule string until no further replacements are possible.\n\n    Parameters\n    ----------\n    molecule : str\n        The input molecule string consisting of characters (assumed to be only\n        'A' and 'B', though the algorithm will work with any characters as long\n        as the target pattern is 'AB').\n\n    Returns\n    -------\n    str\n        The molecule string after all possible 'AB' -> 'BA' rewrites have been\n        applied.\n    \"\"\"\n    # Continue rewriting while the pattern exists in the molecule\n    while 'AB' in molecule:\n        molecule = molecule.replace('AB', 'BA')  # single pass replacement\n    return molecule\n", "reference_tests": [{"type": "basic", "inputs": ["AB"], "output": "BA"}, {"type": "basic", "inputs": ["AAB"], "output": "BAA"}, {"type": "basic", "inputs": ["ABAB"], "output": "BBAA"}, {"type": "edge_case", "inputs": [""], "output": ""}, {"type": "edge_case", "inputs": ["ABBA"], "output": "BBAA"}, {"type": "edge_case", "inputs": ["AAA"], "output": "AAA"}], "sample_type": "code_synthetic", "shards": [{"shard_id": 2, "shard": "Keep repeating the swap until no more AB found"}, {"shard_id": 1, "shard": "Goal change every AB to BA within a molecule string"}, {"shard_id": 4, "shard": "Example input ABAB should finally become BBAA"}, {"shard_id": 3, "shard": "Function takes one string and returns its final version"}], "task": "code", "task_id": "sharded-synthetic-code-34", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "chemical_chain_rewrite"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"\\\"AB\\\"\", \"output\": \"\\\"BA\\\"\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"\\\"AAB\\\"\", \"output\": \"\\\"BAA\\\"\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"\\\"ABAB\\\"\", \"output\": \"\\\"BBAA\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"\\\"\", \"output\": \"\\\"\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"ABBA\\\"\", \"output\": \"\\\"BBAA\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"AAA\\\"\", \"output\": \"\\\"AAA\\\"\", \"testtype\": \"functional\"}]"}, {"problem_id": 16, "category": "greedy", "name": "minimize_delivery_distance", "domain": "geography", "description": "Given sorted list of house coordinates on a line and k post offices, greedily choose k locations from houses minimizing sum of absolute distances. Return chosen coordinates order preserved.", "verified": true, "reference_solution": "def minimize_delivery_distance(houses, k):\n    \"\"\"Return a list with the locations (house coordinates) where the k post offices\n    should be placed so that the sum of the distances from every house to its\n    closest post-office is minimal.  The houses list is already sorted.\n    The returned list keeps the natural left-to-right order.\n    \"\"\"\n    n = len(houses)\n    if k >= n:                     # one office per house \u2013 trivial optimum\n        return houses[:]\n    if k == 1:                     # one office \u2013 choose the median house (lower one if even)\n        return [houses[(n - 1)//2]]\n\n    # Prefix sums to compute interval distances fast\n    prefix = [0]\n    for h in houses:\n        prefix.append(prefix[-1] + h)\n\n    # Pre\u2013compute cost of serving houses[l..r] (inclusive) with one office\n    # placed at its median (lower median when even).\n    cost = [[0]*n for _ in range(n)]\n    for l in range(n):\n        for r in range(l, n):\n            m = (l + r) // 2                       # index of median house (lower if even)\n            # distance for left side\n            left = houses[m]*(m - l) - (prefix[m] - prefix[l])\n            # distance for right side\n            right = (prefix[r+1] - prefix[m+1]) - houses[m]*(r - m)\n            cost[l][r] = left + right\n\n    # DP: dp[p][i] \u2013 minimal distance for first i houses (0..i-1) with p offices\n    INF = float('inf')\n    dp = [[INF]*(n+1) for _ in range(k+1)]\n    prev = [[-1]*(n+1) for _ in range(k+1)]     # where previous segment ends\n    dp[0][0] = 0\n\n    for p in range(1, k+1):\n        # we need at least p houses to place p offices, start index accordingly\n        for i in range(1, n+1):\n            # try every possible split point t (first t houses served by p-1 offices)\n            # segment t .. i-1 served by new office\n            best_val = INF\n            best_t = -1\n            # earliest t is p-1 to ensure there are t houses for p-1 offices\n            for t in range(p-1, i):\n                val = dp[p-1][t] + cost[t][i-1]\n                if val < best_val:\n                    best_val = val\n                    best_t = t\n            dp[p][i] = best_val\n            prev[p][i] = best_t\n\n    # Reconstruct chosen positions (medians of each segment)\n    res = []\n    p, i = k, n\n    while p > 0:\n        t = prev[p][i]\n        l, r = t, i-1\n        m = (l + r) // 2\n        res.append(houses[m])\n        i = t\n        p -= 1\n\n    return res[::-1]", "reference_tests": [{"type": "basic", "inputs": [[1, 2, 3, 4, 5, 100], 2], "output": [3, 100]}, {"type": "basic", "inputs": [[1, 2, 3, 4], 1], "output": [2]}, {"type": "edge_case", "inputs": [[5, 10, 15], 3], "output": [5, 10, 15]}, {"type": "basic", "inputs": [[1, 5, 9, 14, 20, 30], 3], "output": [5, 14, 30]}, {"type": "edge_case", "inputs": [[0, 0, 0, 10], 2], "output": [0, 10]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 3, "shard": "Goal is minimize sum of absolute distances to nearest office"}, {"shard_id": 4, "shard": "Output selected house positions in their original left to right order"}, {"shard_id": 2, "shard": "Input is sorted coordinates of houses plus integer k"}, {"shard_id": 1, "shard": "Need k post offices placed among houses for smallest travel"}], "task": "code", "task_id": "sharded-synthetic-code-16", "verifications": {"full-avg": 0.75, "full-all": {"t-gpt-4.1": [0, 1, 0, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.0, "sharded-all": {"t-gpt-4.1": [0, 0, 0, 0, 0, 0, 0, 0]}}, "acceptable": 1, "metadata": {"func_name": "minimize_delivery_distance"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[1, 2, 3, 4, 5, 100]\\n2\", \"output\": \"[3, 100]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[1, 2, 3, 4]\\n1\", \"output\": \"[2]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[5, 10, 15]\\n3\", \"output\": \"[5, 10, 15]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[1, 5, 9, 14, 20, 30]\\n3\", \"output\": \"[5, 14, 30]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[0, 0, 0, 10]\\n2\", \"output\": \"[0, 10]\", \"testtype\": \"functional\"}]"}, {"problem_id": 25, "category": "list_processing", "name": "split_into_semesters", "domain": "education", "description": "Given course list and semester size n, return nested list of courses per semester. Last semester may have fewer; raise ValueError if n<1.", "verified": true, "reference_solution": "def split_into_semesters(courses, n):\n    \"\"\"Split the list of courses into sublists of length n (a semester).\n    The last sublist may contain fewer than n courses.\n    Raise ValueError if n is not a positive integer (n < 1).\"\"\"\n    if not isinstance(n, int) or n < 1:\n        raise ValueError(\"Semester size must be a positive integer greater than 0\")\n\n    # Build the list of semesters\n    semesters = []\n    for i in range(0, len(courses), n):\n        semesters.append(courses[i:i + n])\n    return semesters", "reference_tests": [{"type": "basic", "inputs": [["CS101", "CS102", "CS103", "CS104"], 2], "output": [["CS101", "CS102"], ["CS103", "CS104"]]}, {"type": "basic", "inputs": [[1, 2, 3, 4, 5, 6, 7], 3], "output": [[1, 2, 3], [4, 5, 6], [7]]}, {"type": "edge_case", "inputs": [[], 2], "output": []}, {"type": "edge_case", "inputs": [["A", "B"], 1], "output": [["A"], ["B"]]}, {"type": "edge_case", "inputs": [[10, 20], 5], "output": [[10, 20]]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 1, "shard": "Need to partition course lineup into equal sized semesters"}, {"shard_id": 3, "shard": "Produce nested list each inner length n final may be smaller"}, {"shard_id": 4, "shard": "If size less than one raise ValueError no grouping performed"}, {"shard_id": 2, "shard": "Accept two arguments course array and positive semester size number"}], "task": "code", "task_id": "sharded-synthetic-code-25", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.875, "sharded-all": {"t-gpt-4.1": [0, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "split_into_semesters"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[\\\"CS101\\\", \\\"CS102\\\", \\\"CS103\\\", \\\"CS104\\\"]\\n2\", \"output\": \"[[\\\"CS101\\\", \\\"CS102\\\"], [\\\"CS103\\\", \\\"CS104\\\"]]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[1, 2, 3, 4, 5, 6, 7]\\n3\", \"output\": \"[[1, 2, 3], [4, 5, 6], [7]]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\\n2\", \"output\": \"[]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"A\\\", \\\"B\\\"]\\n1\", \"output\": \"[[\\\"A\\\"], [\\\"B\\\"]]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[10, 20]\\n5\", \"output\": \"[[10, 20]]\", \"testtype\": \"functional\"}]"}, {"problem_id": 70, "category": "hashing", "name": "weather_cache_key", "domain": "weather", "description": "Generate cache key for query parameters dict by sorting keys alphabetically and SHA1 hashing 'key=value' joined with '&'. Return 16-char prefix.", "verified": true, "reference_solution": "import hashlib\n\ndef weather_cache_key(params: dict) -> str:\n    \"\"\"Generate a 16-character cache-key prefix for a dictionary of query\n    parameters.  The key is built by:\n    1. Sorting the dictionary keys alphabetically.\n    2. Building a query-string of the form \"key=value\" joined by '&'.\n    3. Producing the SHA1 hex digest of that string.\n    4. Returning the first 16 hexadecimal characters (prefix).\n    \"\"\"\n    if not params:\n        return hashlib.sha1(b\"\").hexdigest()[:16]\n\n    # Sort keys and build the canonical query string\n    parts = []\n    for k in sorted(params):\n        v = params[k]\n        # Convert non-string values to string before concatenation\n        parts.append(f\"{k}={v}\")\n    canonical = \"&\".join(parts)\n\n    return hashlib.sha1(canonical.encode()).hexdigest()[:16]\n", "reference_tests": [{"type": "basic", "inputs": [{}], "output": "da39a3ee5e6b4b0d"}, {"type": "edge_case", "inputs": [{}], "output": "da39a3ee5e6b4b0d"}, {"type": "basic", "inputs": [{}], "output": "da39a3ee5e6b4b0d"}, {"type": "edge_case", "inputs": [{}], "output": "da39a3ee5e6b4b0d"}], "sample_type": "code_synthetic", "shards": [{"shard_id": 4, "shard": "Run sha1 on that line output first sixteen hex characters"}, {"shard_id": 2, "shard": "Take dict maybe empty produce hex result always same for no data"}, {"shard_id": 3, "shard": "Sort keys alphabetically glue each as key=value with ampersand"}, {"shard_id": 1, "shard": "Make sixteen character cache key from query data"}], "task": "code", "task_id": "sharded-synthetic-code-70", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "weather_cache_key"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"{}\", \"output\": \"\\\"da39a3ee5e6b4b0d\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"{}\", \"output\": \"\\\"da39a3ee5e6b4b0d\\\"\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"{}\", \"output\": \"\\\"da39a3ee5e6b4b0d\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"{}\", \"output\": \"\\\"da39a3ee5e6b4b0d\\\"\", \"testtype\": \"functional\"}]"}, {"problem_id": 44, "category": "geometry", "name": "gift_box_diagonal", "domain": "ecommerce", "description": "Compute internal diagonal of rectangular box given length, width, height. Return float rounded three decimals.", "verified": true, "reference_solution": "import math\ndef gift_box_diagonal(length, width, height):\n    \"\"\"Return the internal diagonal of a rectangular box rounded to three decimals.\"\"\"\n    diagonal = math.sqrt(length ** 2 + width ** 2 + height ** 2)\n    return round(diagonal, 3)\n", "reference_tests": [{"type": "basic", "inputs": [1, 2, 2], "output": 3.0}, {"type": "basic", "inputs": [3, 4, 12], "output": 13.0}, {"type": "edge_case", "inputs": [1.5, 2.5, 3.5], "output": 4.555}, {"type": "edge_case", "inputs": [0, 0, 0], "output": 0.0}, {"type": "edge_case", "inputs": [0.333, 0.444, 0.555], "output": 0.785}], "sample_type": "code_synthetic", "shards": [{"shard_id": 2, "shard": "Inputs are three numbers giving length width and height of the box"}, {"shard_id": 1, "shard": "Find the internal diagonal inside a rectangular prism shaped gift box"}, {"shard_id": 3, "shard": "Compute square root of sum of squares of the three numbers"}, {"shard_id": 4, "shard": "Output float rounded to three decimal digits like thirteen point one two three"}], "task": "code", "task_id": "sharded-synthetic-code-44", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.0, "sharded-all": {"t-gpt-4.1": [0, 0, 0, 0, 0, 0, 0, 0]}}, "acceptable": 1, "metadata": {"func_name": "gift_box_diagonal"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"1\\n2\\n2\", \"output\": \"3.0\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"3\\n4\\n12\", \"output\": \"13.0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"1.5\\n2.5\\n3.5\", \"output\": \"4.555\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"0\\n0\\n0\", \"output\": \"0.0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"0.333\\n0.444\\n0.555\", \"output\": \"0.785\", \"testtype\": \"functional\"}]"}, {"problem_id": 23, "category": "math", "name": "average_grade_drop", "domain": "education", "description": "Given list of ordered test scores, compute largest drop between any two consecutive scores, returning 0 if scores never decrease.", "verified": true, "reference_solution": "def average_grade_drop(scores):\n    \"\"\"Compute the largest drop between any two consecutive test scores.\n\n    Parameters\n    ----------\n    scores : list of int or float\n        Ordered list of test scores.\n\n    Returns\n    -------\n    int or float\n        The maximum decrease between consecutive scores. Returns 0 if there is\n        no decrease or the list has fewer than two elements.\n    \"\"\"\n    if not scores or len(scores) < 2:\n        return 0\n\n    max_drop = 0\n    for prev, curr in zip(scores, scores[1:]):\n        drop = prev - curr\n        if drop > max_drop:\n            max_drop = drop\n    return max_drop", "reference_tests": [{"type": "basic", "inputs": [[100, 90, 95, 80]], "output": 15}, {"type": "basic", "inputs": [[1, 2, 3, 4]], "output": 0}, {"type": "edge_case", "inputs": [[80]], "output": 0}, {"type": "edge_case", "inputs": [[]], "output": 0}, {"type": "basic", "inputs": [[90, 70, 70, 60]], "output": 20}, {"type": "edge_case", "inputs": [[100, 90, 90, 95, 85, 85, 70]], "output": 15}], "sample_type": "code_synthetic", "shards": [{"shard_id": 2, "shard": "You receive a list of numbers in given order"}, {"shard_id": 3, "shard": "If scores never decrease or list tiny return zero"}, {"shard_id": 4, "shard": "Example 100 90 95 80 should reply 15"}, {"shard_id": 1, "shard": "Find biggest drop between consecutive exam scores"}], "task": "code", "task_id": "sharded-synthetic-code-23", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "average_grade_drop"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[100, 90, 95, 80]\", \"output\": \"15\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[1, 2, 3, 4]\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[80]\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[90, 70, 70, 60]\", \"output\": \"20\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[100, 90, 90, 95, 85, 85, 70]\", \"output\": \"15\", \"testtype\": \"functional\"}]"}, {"problem_id": 37, "category": "formatting", "name": "pad_tracking_numbers", "domain": "logistics", "description": "Ensure each tracking number has exactly 12 digits by left-padding with zeros. Return amended list.", "verified": true, "reference_solution": "def pad_tracking_numbers(tracking_numbers):\n    \"\"\"Return list where every tracking number is a 12-digit string padded with leading zeros.\n    Accepts a list of integers or strings representing non-negative tracking numbers.\n    \"\"\"\n    padded = []\n    for tn in tracking_numbers:\n        # Convert to string safely\n        tn_str = str(tn)\n        # If it already has 12+ characters, keep as is; otherwise pad on the left\n        if len(tn_str) < 12:\n            tn_str = tn_str.zfill(12)\n        padded.append(tn_str)\n    return padded", "reference_tests": [{"type": "basic", "inputs": [["12345", "987654321"]], "output": ["000000012345", "000987654321"]}, {"type": "basic", "inputs": [[123, 456789012345]], "output": ["000000000123", "456789012345"]}, {"type": "edge_case", "inputs": [[]], "output": []}, {"type": "edge_case", "inputs": [["000123456789"]], "output": ["000123456789"]}, {"type": "edge_case", "inputs": [[0]], "output": ["000000000000"]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 2, "shard": "Input list holds numbers or digit strings never negative values"}, {"shard_id": 1, "shard": "Goal make every parcel number show twelve digits no matter input size"}, {"shard_id": 4, "shard": "So 12345 turns into 000000012345 and empty list stays empty"}, {"shard_id": 3, "shard": "Need to add zeroes on the left until length becomes twelve"}], "task": "code", "task_id": "sharded-synthetic-code-37", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "pad_tracking_numbers"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[\\\"12345\\\", \\\"987654321\\\"]\", \"output\": \"[\\\"000000012345\\\", \\\"000987654321\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[123, 456789012345]\", \"output\": \"[\\\"000000000123\\\", \\\"456789012345\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\", \"output\": \"[]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"000123456789\\\"]\", \"output\": \"[\\\"000123456789\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[0]\", \"output\": \"[\\\"000000000000\\\"]\", \"testtype\": \"functional\"}]"}, {"problem_id": 17, "category": "formatting", "name": "format_country_codes", "domain": "geography", "description": "Convert list of two-letter country codes to uppercase, group them three per line separated by commas, final line may have fewer. Return the multiline string with no trailing comma.", "verified": true, "reference_solution": "def format_country_codes(codes):\n    \"\"\"Convert country codes to uppercase and arrange them three per line.\n\n    Parameters\n    ----------\n    codes : list of str\n        List containing two-letter (or generally short) country codes.\n\n    Returns\n    -------\n    str\n        Multiline string where codes are uppercase, grouped three per line\n        separated by commas. No trailing comma or trailing newline is added.\n    \"\"\"\n    # Upper-case all codes first\n    upper_codes = [code.upper() for code in codes]\n\n    # Group into chunks of three and join appropriately\n    lines = []\n    for i in range(0, len(upper_codes), 3):\n        chunk = upper_codes[i:i + 3]\n        lines.append(\",\".join(chunk))\n\n    # Join lines with newline, but if no codes return empty string\n    return \"\\n\".join(lines)\n", "reference_tests": [{"type": "basic", "inputs": [["us", "ca", "mx"]], "output": "US,CA,MX"}, {"type": "basic", "inputs": [["us", "ca", "mx", "uk", "fr"]], "output": "US,CA,MX\nUK,FR"}, {"type": "edge_case", "inputs": [["aa", "bb", "cc", "dd", "ee", "ff"]], "output": "AA,BB,CC\nDD,EE,FF"}, {"type": "edge_case", "inputs": [["in"]], "output": "IN"}, {"type": "edge_case", "inputs": [[]], "output": ""}], "sample_type": "code_synthetic", "shards": [{"shard_id": 4, "shard": "Last line can hold fewer codes empty input returns blank string"}, {"shard_id": 3, "shard": "Place three codes per line joined by comma leaving no extra comma at end"}, {"shard_id": 1, "shard": "Take a list of country codes and give back a neat multiline string"}, {"shard_id": 2, "shard": "Make every code uppercase before doing anything else"}], "task": "code", "task_id": "sharded-synthetic-code-17", "verifications": {"full-avg": 0.875, "full-all": {"t-gpt-4.1": [1, 1, 1, 0, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.5, "sharded-all": {"t-gpt-4.1": [1, 1, 0, 1, 0, 0, 1, 0]}}, "acceptable": 1, "metadata": {"func_name": "format_country_codes"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[\\\"us\\\", \\\"ca\\\", \\\"mx\\\"]\", \"output\": \"\\\"US,CA,MX\\\"\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[\\\"us\\\", \\\"ca\\\", \\\"mx\\\", \\\"uk\\\", \\\"fr\\\"]\", \"output\": \"\\\"US,CA,MX\\\\nUK,FR\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"aa\\\", \\\"bb\\\", \\\"cc\\\", \\\"dd\\\", \\\"ee\\\", \\\"ff\\\"]\", \"output\": \"\\\"AA,BB,CC\\\\nDD,EE,FF\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"in\\\"]\", \"output\": \"\\\"IN\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\", \"output\": \"\\\"\\\"\", \"testtype\": \"functional\"}]"}, {"problem_id": 41, "category": "sorting", "name": "sort_products_by_margin", "domain": "ecommerce", "description": "Given list of dicts with cost and price, sort products by descending profit margin percentage. Break ties by ascending product id.", "verified": true, "reference_solution": "def sort_products_by_margin(products):\n    \"\"\"Sort a list of product dictionaries by descending profit margin percentage.\n\n    Each product dict is expected to have at least these keys:\n        - 'id': a value that can be compared (typically an int)\n        - 'cost': numeric cost (>=0)\n        - 'price': numeric selling price\n\n    The profit margin percentage is computed as (price - cost) / cost.\n    Products are ordered primarily by descending margin, and secondarily by\n    ascending id in case of ties.\n    The function returns a new sorted list and leaves the original untouched.\n    \"\"\"\n    def margin(product):\n        cost = product.get('cost', 0)\n        price = product.get('price', 0)\n        if cost == 0:\n            # Define infinite margin for zero cost but higher price, otherwise 0\n            return float('inf') if price > 0 else 0.0\n        return (price - cost) / cost\n\n    # Sort by (-margin, id) so that larger margin comes first and id ascending breaks ties\n    return sorted(products, key=lambda p: (-margin(p), p.get('id')))\n", "reference_tests": [{"type": "basic", "inputs": [[{"id": 1, "cost": 50, "price": 100}, {"id": 2, "cost": 30, "price": 60}, {"id": 3, "cost": 20, "price": 25}]], "output": [{"id": 1, "cost": 50, "price": 100}, {"id": 2, "cost": 30, "price": 60}, {"id": 3, "cost": 20, "price": 25}]}, {"type": "basic", "inputs": [[{"id": 10, "cost": 80, "price": 120}, {"id": 11, "cost": 40, "price": 60}, {"id": 12, "cost": 50, "price": 100}]], "output": [{"id": 12, "cost": 50, "price": 100}, {"id": 10, "cost": 80, "price": 120}, {"id": 11, "cost": 40, "price": 60}]}, {"type": "edge_case", "inputs": [[{"id": 4, "cost": 20, "price": 30}, {"id": 5, "cost": 40, "price": 60}, {"id": 6, "cost": 50, "price": 60}]], "output": [{"id": 4, "cost": 20, "price": 30}, {"id": 5, "cost": 40, "price": 60}, {"id": 6, "cost": 50, "price": 60}]}, {"type": "edge_case", "inputs": [[{"id": 99, "cost": 10, "price": 15}]], "output": [{"id": 99, "cost": 10, "price": 15}]}, {"type": "edge_case", "inputs": [[]], "output": []}], "sample_type": "code_synthetic", "shards": [{"shard_id": 3, "shard": "Profit percent equals price minus cost divided by cost larger value comes earlier"}, {"shard_id": 1, "shard": "Goal sort a product list by best profit percentage first"}, {"shard_id": 4, "shard": "If profits equal choose smaller id otherwise keep order produce new sorted list"}, {"shard_id": 2, "shard": "Each product record has id cost price all numeric values"}], "task": "code", "task_id": "sharded-synthetic-code-41", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.75, "sharded-all": {"t-gpt-4.1": [1, 0, 1, 1, 0, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "sort_products_by_margin"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[{\\\"id\\\": 1, \\\"cost\\\": 50, \\\"price\\\": 100}, {\\\"id\\\": 2, \\\"cost\\\": 30, \\\"price\\\": 60}, {\\\"id\\\": 3, \\\"cost\\\": 20, \\\"price\\\": 25}]\", \"output\": \"[{\\\"id\\\": 1, \\\"cost\\\": 50, \\\"price\\\": 100}, {\\\"id\\\": 2, \\\"cost\\\": 30, \\\"price\\\": 60}, {\\\"id\\\": 3, \\\"cost\\\": 20, \\\"price\\\": 25}]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[{\\\"id\\\": 10, \\\"cost\\\": 80, \\\"price\\\": 120}, {\\\"id\\\": 11, \\\"cost\\\": 40, \\\"price\\\": 60}, {\\\"id\\\": 12, \\\"cost\\\": 50, \\\"price\\\": 100}]\", \"output\": \"[{\\\"id\\\": 12, \\\"cost\\\": 50, \\\"price\\\": 100}, {\\\"id\\\": 10, \\\"cost\\\": 80, \\\"price\\\": 120}, {\\\"id\\\": 11, \\\"cost\\\": 40, \\\"price\\\": 60}]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[{\\\"id\\\": 4, \\\"cost\\\": 20, \\\"price\\\": 30}, {\\\"id\\\": 5, \\\"cost\\\": 40, \\\"price\\\": 60}, {\\\"id\\\": 6, \\\"cost\\\": 50, \\\"price\\\": 60}]\", \"output\": \"[{\\\"id\\\": 4, \\\"cost\\\": 20, \\\"price\\\": 30}, {\\\"id\\\": 5, \\\"cost\\\": 40, \\\"price\\\": 60}, {\\\"id\\\": 6, \\\"cost\\\": 50, \\\"price\\\": 60}]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[{\\\"id\\\": 99, \\\"cost\\\": 10, \\\"price\\\": 15}]\", \"output\": \"[{\\\"id\\\": 99, \\\"cost\\\": 10, \\\"price\\\": 15}]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\", \"output\": \"[]\", \"testtype\": \"functional\"}]"}, {"problem_id": 98, "category": "validation", "name": "validate_rating_string", "domain": "entertainment", "description": "Check rating string like 'PG-13', ensuring prefix in {G,PG,PG-13,R,NC-17} exactly matches. Return bool.", "verified": true, "reference_solution": "def validate_rating_string(rating: str) -> bool:\n    \"\"\"Return True iff the provided rating string is exactly one of the\n    MPAA ratings: 'G', 'PG', 'PG-13', 'R', or 'NC-17'. The match is\n    case-sensitive and must be an exact match (no surrounding spaces).\"\"\"\n    valid_ratings = {\"G\", \"PG\", \"PG-13\", \"R\", \"NC-17\"}\n    return rating in valid_ratings\n", "reference_tests": [{"type": "basic", "inputs": ["G"], "output": true}, {"type": "basic", "inputs": ["PG-13"], "output": true}, {"type": "edge_case", "inputs": ["pg"], "output": false}, {"type": "edge_case", "inputs": ["PG13"], "output": false}, {"type": "edge_case", "inputs": ["NC-17"], "output": true}, {"type": "edge_case", "inputs": ["NC -17"], "output": false}], "sample_type": "code_synthetic", "shards": [{"shard_id": 3, "shard": "Match must be identical including capital letters no padding spaces"}, {"shard_id": 4, "shard": "Output boolean true when tag valid otherwise false"}, {"shard_id": 2, "shard": "Recognize tags G PG PG dash thirteen R and NC dash seventeen"}, {"shard_id": 1, "shard": "Check a film rating text matches approved standard tags exactly"}], "task": "code", "task_id": "sharded-synthetic-code-98", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.875, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 0, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "validate_rating_string"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"\\\"G\\\"\", \"output\": \"true\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"\\\"PG-13\\\"\", \"output\": \"true\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"pg\\\"\", \"output\": \"false\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"PG13\\\"\", \"output\": \"false\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"NC-17\\\"\", \"output\": \"true\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"NC -17\\\"\", \"output\": \"false\", \"testtype\": \"functional\"}]"}, {"problem_id": 61, "category": "sorting", "name": "sort_tracks_by_bpm", "domain": "music", "description": "Sort track dicts by BPM ascending, ties broken by descending popularity score.", "verified": true, "reference_solution": "def sort_tracks_by_bpm(tracks):\n    \"\"\"Sort a list of track dictionaries by BPM in ascending order.\n    If multiple tracks have the same BPM, sort those tracks by popularity\n    in descending order.\n\n    Each track dictionary is expected to have at least two keys:\n        - 'bpm': numeric value (int or float)\n        - 'popularity': numeric value (int or float)\n\n    The function returns a new list that is sorted accordingly.\n    \"\"\"\n    # The key uses ascending BPM (x['bpm']) and negative popularity to achieve\n    # descending popularity for tracks with identical BPM.\n    return sorted(tracks, key=lambda x: (x[\"bpm\"], -x[\"popularity\"]))", "reference_tests": [{"type": "basic", "inputs": [[{"title": "Track A", "bpm": 120, "popularity": 80}, {"title": "Track B", "bpm": 110, "popularity": 90}, {"title": "Track C", "bpm": 120, "popularity": 85}]], "output": [{"title": "Track B", "bpm": 110, "popularity": 90}, {"title": "Track C", "bpm": 120, "popularity": 85}, {"title": "Track A", "bpm": 120, "popularity": 80}]}, {"type": "basic", "inputs": [[{"title": "T1", "bpm": 100, "popularity": 50}, {"title": "T2", "bpm": 100, "popularity": 60}]], "output": [{"title": "T2", "bpm": 100, "popularity": 60}, {"title": "T1", "bpm": 100, "popularity": 50}]}, {"type": "edge_case", "inputs": [[]], "output": []}, {"type": "edge_case", "inputs": [[{"title": "Solo", "bpm": 128, "popularity": 70}]], "output": [{"title": "Solo", "bpm": 128, "popularity": 70}]}, {"type": "edge_case", "inputs": [[{"title": "LowPop", "bpm": 90, "popularity": -5}, {"title": "HighPop", "bpm": 90, "popularity": 0}, {"title": "Fast", "bpm": 150, "popularity": 100}]], "output": [{"title": "HighPop", "bpm": 90, "popularity": 0}, {"title": "LowPop", "bpm": 90, "popularity": -5}, {"title": "Fast", "bpm": 150, "popularity": 100}]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 1, "shard": "Need to reorder music track info list by tempo then fame"}, {"shard_id": 2, "shard": "Each item is a dictionary holding bpm number and popularity score"}, {"shard_id": 4, "shard": "When bpm equal pick track with bigger popularity before others"}, {"shard_id": 3, "shard": "Primary sort is lower bpm should appear earlier in result"}], "task": "code", "task_id": "sharded-synthetic-code-61", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "sort_tracks_by_bpm"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[{\\\"title\\\": \\\"Track A\\\", \\\"bpm\\\": 120, \\\"popularity\\\": 80}, {\\\"title\\\": \\\"Track B\\\", \\\"bpm\\\": 110, \\\"popularity\\\": 90}, {\\\"title\\\": \\\"Track C\\\", \\\"bpm\\\": 120, \\\"popularity\\\": 85}]\", \"output\": \"[{\\\"title\\\": \\\"Track B\\\", \\\"bpm\\\": 110, \\\"popularity\\\": 90}, {\\\"title\\\": \\\"Track C\\\", \\\"bpm\\\": 120, \\\"popularity\\\": 85}, {\\\"title\\\": \\\"Track A\\\", \\\"bpm\\\": 120, \\\"popularity\\\": 80}]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[{\\\"title\\\": \\\"T1\\\", \\\"bpm\\\": 100, \\\"popularity\\\": 50}, {\\\"title\\\": \\\"T2\\\", \\\"bpm\\\": 100, \\\"popularity\\\": 60}]\", \"output\": \"[{\\\"title\\\": \\\"T2\\\", \\\"bpm\\\": 100, \\\"popularity\\\": 60}, {\\\"title\\\": \\\"T1\\\", \\\"bpm\\\": 100, \\\"popularity\\\": 50}]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\", \"output\": \"[]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[{\\\"title\\\": \\\"Solo\\\", \\\"bpm\\\": 128, \\\"popularity\\\": 70}]\", \"output\": \"[{\\\"title\\\": \\\"Solo\\\", \\\"bpm\\\": 128, \\\"popularity\\\": 70}]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[{\\\"title\\\": \\\"LowPop\\\", \\\"bpm\\\": 90, \\\"popularity\\\": -5}, {\\\"title\\\": \\\"HighPop\\\", \\\"bpm\\\": 90, \\\"popularity\\\": 0}, {\\\"title\\\": \\\"Fast\\\", \\\"bpm\\\": 150, \\\"popularity\\\": 100}]\", \"output\": \"[{\\\"title\\\": \\\"HighPop\\\", \\\"bpm\\\": 90, \\\"popularity\\\": 0}, {\\\"title\\\": \\\"LowPop\\\", \\\"bpm\\\": 90, \\\"popularity\\\": -5}, {\\\"title\\\": \\\"Fast\\\", \\\"bpm\\\": 150, \\\"popularity\\\": 100}]\", \"testtype\": \"functional\"}]"}, {"problem_id": 2, "category": "string_manipulation", "name": "normalize_financial_tickers", "domain": "finance", "description": "Receive mixed-case stock ticker symbols possibly containing spaces or punctuation. Return a list with duplicates removed, every symbol upper-cased, and kept in their first appearance order after cleaning.", "verified": true, "reference_solution": "import re\n\ndef normalize_financial_tickers(tickers):\n    \"\"\"Normalize a list of financial tickers.\n\n    1. Strip every character that is not a letter or digit.\n    2. Convert the remaining string to upper-case.\n    3. Skip empty results produced after cleaning.\n    4. Preserve the first appearance order while removing duplicates.\n    \"\"\"\n    seen = set()\n    normalized = []\n\n    for symbol in tickers:\n        # Remove any character that is not a letter or digit, then upper-case\n        cleaned = re.sub(r\"[^A-Za-z0-9]\", \"\", str(symbol)).upper()\n        if cleaned and cleaned not in seen:\n            seen.add(cleaned)\n            normalized.append(cleaned)\n\n    return normalized\n", "reference_tests": [{"type": "basic", "inputs": [["aapl", "MSFT ", "goog"]], "output": ["AAPL", "MSFT", "GOOG"]}, {"type": "basic", "inputs": [["Aapl", "a a p l", "AAP L", "msft"]], "output": ["AAPL", "MSFT"]}, {"type": "edge_case", "inputs": [["brk.b", "BRK B", "Brk-B"]], "output": ["BRKB"]}, {"type": "edge_case", "inputs": [["", " ", "!!!", "tsla"]], "output": ["TSLA"]}, {"type": "edge_case", "inputs": [["TSLA", "TSLA", "TSLA"]], "output": ["TSLA"]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 4, "shard": "Reject later duplicates so result shows each symbol only once"}, {"shard_id": 3, "shard": "Skip any symbol that becomes empty after the cleanup step"}, {"shard_id": 2, "shard": "Delete every non letter or digit then change to upper case"}, {"shard_id": 1, "shard": "Clean a list of ticker strings while keeping first seen order"}], "task": "code", "task_id": "sharded-synthetic-code-2", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "normalize_financial_tickers"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[\\\"aapl\\\", \\\"MSFT \\\", \\\"goog\\\"]\", \"output\": \"[\\\"AAPL\\\", \\\"MSFT\\\", \\\"GOOG\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[\\\"Aapl\\\", \\\"a a p l\\\", \\\"AAP L\\\", \\\"msft\\\"]\", \"output\": \"[\\\"AAPL\\\", \\\"MSFT\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"brk.b\\\", \\\"BRK B\\\", \\\"Brk-B\\\"]\", \"output\": \"[\\\"BRKB\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"\\\", \\\" \\\", \\\"!!!\\\", \\\"tsla\\\"]\", \"output\": \"[\\\"TSLA\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"TSLA\\\", \\\"TSLA\\\", \\\"TSLA\\\"]\", \"output\": \"[\\\"TSLA\\\"]\", \"testtype\": \"functional\"}]"}, {"problem_id": 30, "category": "hashing", "name": "unique_player_signature", "domain": "gaming", "description": "Concatenate player username with join-date, hash using MD5, return first eight characters uppercase.", "verified": true, "reference_solution": "import hashlib\n\ndef unique_player_signature(username, join_date):\n    \"\"\"Return the first eight characters (uppercase) of the MD5 hash of the\n    concatenation of username and join_date. Both inputs are converted to\n    strings before concatenation to ensure robustness.\n    \"\"\"\n    # Ensure inputs are strings\n    combined = str(username) + str(join_date)\n    # Generate MD5 hash\n    md5_hash = hashlib.md5(combined.encode('utf-8')).hexdigest()\n    # Return first eight characters in uppercase\n    return md5_hash[:8].upper()", "reference_tests": [{"type": "basic", "inputs": ["a", ""], "output": "0CC175B9"}, {"type": "basic", "inputs": ["", ""], "output": "D41D8CD9"}, {"type": "basic", "inputs": ["ab", "c"], "output": "90015098"}, {"type": "edge_case", "inputs": ["", "password"], "output": "5F4DCC3B"}, {"type": "edge_case", "inputs": ["a", "b"], "output": "187EF443"}], "sample_type": "code_synthetic", "shards": [{"shard_id": 4, "shard": "Keep only first eight characters convert to uppercase and present it"}, {"shard_id": 1, "shard": "Make a reproducible tag by merging a players username with when they joined"}, {"shard_id": 2, "shard": "The function takes two strings username and date and returns eight character code"}, {"shard_id": 3, "shard": "Generate md5 digest from the concatenated strings to build the identifier"}], "task": "code", "task_id": "sharded-synthetic-code-30", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.5, "sharded-all": {"t-gpt-4.1": [0, 1, 1, 0, 0, 1, 1, 0]}}, "acceptable": 1, "metadata": {"func_name": "unique_player_signature"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"\\\"a\\\"\\n\\\"\\\"\", \"output\": \"\\\"0CC175B9\\\"\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"\\\"\\\"\\n\\\"\\\"\", \"output\": \"\\\"D41D8CD9\\\"\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"\\\"ab\\\"\\n\\\"c\\\"\", \"output\": \"\\\"90015098\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"\\\"\\n\\\"password\\\"\", \"output\": \"\\\"5F4DCC3B\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"a\\\"\\n\\\"b\\\"\", \"output\": \"\\\"187EF443\\\"\", \"testtype\": \"functional\"}]"}, {"problem_id": 7, "category": "date_time", "name": "next_vaccination_day", "domain": "healthcare", "description": "Given a starting date string YYYY-MM-DD and integer interval days, return next vaccination date that never falls on weekend (Saturday or Sunday). Skip weekends by pushing forward until Monday.", "verified": true, "reference_solution": "from datetime import datetime, timedelta\n\ndef next_vaccination_day(start_date: str, interval_days: int) -> str:\n    \"\"\"Return the next vaccination date (YYYY-MM-DD) that never falls on a weekend.\n    1. start_date is a string in 'YYYY-MM-DD' format.\n    2. interval_days is the number of days to add to start_date.\n    3. If the resulting date is Saturday (weekday==5) or Sunday (weekday==6),\n       push it forward to the following Monday.\n    \"\"\"\n    # Parse the input date\n    date_obj = datetime.strptime(start_date, \"%Y-%m-%d\").date()\n\n    # Add the interval\n    candidate = date_obj + timedelta(days=interval_days)\n\n    # If candidate falls on weekend, push forward to Monday\n    weekday = candidate.weekday()  # Monday=0, Sunday=6\n    if weekday == 5:  # Saturday -> push 2 days\n        candidate += timedelta(days=2)\n    elif weekday == 6:  # Sunday -> push 1 day\n        candidate += timedelta(days=1)\n\n    return candidate.strftime(\"%Y-%m-%d\")\n", "reference_tests": [{"type": "basic", "inputs": ["2023-01-01", 28], "output": "2023-01-30"}, {"type": "basic", "inputs": ["2023-08-10", 2], "output": "2023-08-14"}, {"type": "edge_case", "inputs": ["2023-08-11", 1], "output": "2023-08-14"}, {"type": "edge_case", "inputs": ["2023-08-12", 0], "output": "2023-08-14"}, {"type": "edge_case", "inputs": ["2022-12-12", 5], "output": "2022-12-19"}, {"type": "edge_case", "inputs": ["2023-12-29", 2], "output": "2024-01-01"}], "sample_type": "code_synthetic", "shards": [{"shard_id": 4, "shard": "Return the final date in same dashed format"}, {"shard_id": 2, "shard": "You start with YYYY-MM-DD and an integer count of days"}, {"shard_id": 1, "shard": "Find next vaccine day that avoids weekend"}, {"shard_id": 3, "shard": "After adding days skip forward if landing on Saturday or Sunday"}], "task": "code", "task_id": "sharded-synthetic-code-7", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.875, "sharded-all": {"t-gpt-4.1": [1, 1, 0, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "next_vaccination_day"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"\\\"2023-01-01\\\"\\n28\", \"output\": \"\\\"2023-01-30\\\"\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"\\\"2023-08-10\\\"\\n2\", \"output\": \"\\\"2023-08-14\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"2023-08-11\\\"\\n1\", \"output\": \"\\\"2023-08-14\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"2023-08-12\\\"\\n0\", \"output\": \"\\\"2023-08-14\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"2022-12-12\\\"\\n5\", \"output\": \"\\\"2022-12-19\\\"\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"2023-12-29\\\"\\n2\", \"output\": \"\\\"2024-01-01\\\"\", \"testtype\": \"functional\"}]"}, {"problem_id": 32, "category": "bitwise", "name": "toggle_experiment_flags", "domain": "science", "description": "Given integer flag state and list of bit positions, toggle each bit. Bits are 0-indexed from right.", "verified": true, "reference_solution": "def toggle_experiment_flags(flag_state, positions):\n    \"\"\"Toggle bits at the given positions in flag_state.\n\n    Args:\n        flag_state (int): The original integer containing flag bits.\n        positions (list[int]): List of 0-indexed bit positions to toggle.\n\n    Returns:\n        int: The resulting integer after toggling the specified bits.\n    \"\"\"\n    for pos in positions:\n        flag_state ^= 1 << pos  # XOR with a mask flips the bit at 'pos'\n    return flag_state", "reference_tests": [{"type": "basic", "inputs": [5, [0]], "output": 4}, {"type": "basic", "inputs": [0, [1, 3]], "output": 10}, {"type": "edge_case", "inputs": [6, [1, 2, 1]], "output": 2}, {"type": "edge_case", "inputs": [15, []], "output": 15}, {"type": "edge_case", "inputs": [1, [10]], "output": 1025}], "sample_type": "code_synthetic", "shards": [{"shard_id": 1, "shard": "Need to change specific bits of given flag integer"}, {"shard_id": 4, "shard": "When list empty return original else apply bit toggles to all"}, {"shard_id": 2, "shard": "Provide list of zero indexed positions from least significant side"}, {"shard_id": 3, "shard": "Flip bit at each listed spot then output resulting integer value"}], "task": "code", "task_id": "sharded-synthetic-code-32", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.875, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 0, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "toggle_experiment_flags"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"5\\n[0]\", \"output\": \"4\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"0\\n[1, 3]\", \"output\": \"10\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"6\\n[1, 2, 1]\", \"output\": \"2\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"15\\n[]\", \"output\": \"15\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"1\\n[10]\", \"output\": \"1025\", \"testtype\": \"functional\"}]"}, {"problem_id": 28, "category": "parsing", "name": "decode_save_file", "domain": "gaming", "description": "Parse save-file string of key=value pairs separated by semicolons; numeric values should become ints. Return dictionary with keys preserved order of appearance.", "verified": true, "reference_solution": "def decode_save_file(save_str):\n    \"\"\"Decode a save-file string of the form 'key=value;key2=value2;...'.\n    Numeric values (optionally starting with a minus sign) are converted\n    to ints. The order of keys is preserved in the returned dictionary.\n    \"\"\"\n    result = {}\n    if not save_str:\n        return result\n\n    # Split on semicolons; ignore empty segments (e.g., trailing ';')\n    for segment in save_str.split(';'):\n        if not segment:\n            continue\n        if '=' not in segment:\n            # If no '=' present, treat whole segment as a key with empty string value\n            key, value = segment, ''\n        else:\n            key, value = segment.split('=', 1)\n        # Strip surrounding whitespace from key/value\n        key = key.strip()\n        value = value.strip()\n\n        # Detect integer (handles optional leading '-')\n        if value.lstrip('-').isdigit():\n            try:\n                value = int(value)\n            except ValueError:\n                pass  # Keep original string if conversion fails for any reason\n        result[key] = value\n    return result", "reference_tests": [{"type": "basic", "inputs": ["health=100;mana=50;name=Link"], "output": {"health": 100, "mana": 50, "name": "Link"}}, {"type": "edge_case", "inputs": ["lives=-3;level=2"], "output": {"lives": -3, "level": 2}}, {"type": "edge_case", "inputs": ["code=007bond;secret=42"], "output": {"code": "007bond", "secret": 42}}, {"type": "edge_case", "inputs": ["x=1;y=2;z=three;"], "output": {"x": 1, "y": 2, "z": "three"}}, {"type": "edge_case", "inputs": [""], "output": {}}], "sample_type": "code_synthetic", "shards": [{"shard_id": 2, "shard": "Pairs shaped like key=value appear separated by semicolons"}, {"shard_id": 1, "shard": "Need dictionary from a save string keys keep listed order"}, {"shard_id": 4, "shard": "Blank input returns empty dict plus trailing separators ignored"}, {"shard_id": 3, "shard": "If value looks like whole number treat it as int else keep text"}], "task": "code", "task_id": "sharded-synthetic-code-28", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 0.875, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 0, 1, 1, 1]}, "sharded-avg": 0.875, "sharded-all": {"t-gpt-4.1": [0, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "decode_save_file"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"\\\"health=100;mana=50;name=Link\\\"\", \"output\": \"{\\\"health\\\": 100, \\\"mana\\\": 50, \\\"name\\\": \\\"Link\\\"}\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"lives=-3;level=2\\\"\", \"output\": \"{\\\"lives\\\": -3, \\\"level\\\": 2}\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"code=007bond;secret=42\\\"\", \"output\": \"{\\\"code\\\": \\\"007bond\\\", \\\"secret\\\": 42}\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"x=1;y=2;z=three;\\\"\", \"output\": \"{\\\"x\\\": 1, \\\"y\\\": 2, \\\"z\\\": \\\"three\\\"}\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"\\\"\", \"output\": \"{}\", \"testtype\": \"functional\"}]"}, {"problem_id": 84, "category": "geometry", "name": "intersection_area_two_circles", "domain": "transport", "description": "Given centers and radii of two circles, compute intersection area rounded 4 decimals. Assume inputs guarantee some overlap.", "verified": true, "reference_solution": "import math\n\ndef intersection_area_two_circles(x1, y1, r1, x2, y2, r2):\n    \"\"\"Return the area of intersection of two circles rounded to 4 decimals.\n    Parameters are centre coordinates and radii: (x1, y1, r1, x2, y2, r2)\n    \"\"\"\n    # Distance between centres\n    dx = x2 - x1\n    dy = y2 - y1\n    d = math.hypot(dx, dy)\n\n    # No overlap\n    if d >= r1 + r2:\n        return 0.0\n\n    # One circle completely inside the other (includes coincident centres)\n    if d <= abs(r1 - r2):\n        return round(math.pi * min(r1, r2) ** 2, 4)\n\n    # Partial overlap\n    # Formula components\n    alpha = math.acos((d**2 + r1**2 - r2**2) / (2 * d * r1))\n    beta = math.acos((d**2 + r2**2 - r1**2) / (2 * d * r2))\n\n    area1 = r1**2 * alpha\n    area2 = r2**2 * beta\n\n    # Segment of intersection (lens) area\n    area3 = 0.5 * math.sqrt(\n        max(0.0, (-d + r1 + r2) * (d + r1 - r2) * (d - r1 + r2) * (d + r1 + r2))\n    )\n\n    intersection = area1 + area2 - area3\n    return round(intersection, 4)\n", "reference_tests": [{"type": "basic", "inputs": [0, 0, 2, 3, 0, 2], "output": 1.8132}, {"type": "basic", "inputs": [0, 0, 3, 5, 0, 4], "output": 6.6417}, {"type": "edge_case", "inputs": [0, 0, 1, 1.5, 0, 1], "output": 0.4533}, {"type": "edge_case", "inputs": [0, 0, 5, 1, 1, 2], "output": 12.5664}, {"type": "edge_case", "inputs": [0, 0, 1, 0, 0, 1], "output": 3.1416}], "sample_type": "code_synthetic", "shards": [{"shard_id": 4, "shard": "You can trust circles definitely overlap at least partly"}, {"shard_id": 1, "shard": "Compute how much two circles intersect area wise"}, {"shard_id": 2, "shard": "Input six numbers center x y and radius for each circle"}, {"shard_id": 3, "shard": "Output single float being the intersection surface rounded to four decimals"}], "task": "code", "task_id": "sharded-synthetic-code-84", "verifications": {"full-avg": 0.875, "full-all": {"t-gpt-4.1": [1, 0, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.375, "sharded-all": {"t-gpt-4.1": [0, 1, 0, 0, 1, 0, 1, 0]}}, "acceptable": 1, "metadata": {"func_name": "intersection_area_two_circles"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"0\\n0\\n2\\n3\\n0\\n2\", \"output\": \"1.8132\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"0\\n0\\n3\\n5\\n0\\n4\", \"output\": \"6.6417\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"0\\n0\\n1\\n1.5\\n0\\n1\", \"output\": \"0.4533\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"0\\n0\\n5\\n1\\n1\\n2\", \"output\": \"12.5664\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"0\\n0\\n1\\n0\\n0\\n1\", \"output\": \"3.1416\", \"testtype\": \"functional\"}]"}, {"problem_id": 89, "category": "searching", "name": "locate_weeds_cluster", "domain": "agriculture", "description": "Given grid of 0/1, find size of largest connected 1-cluster using BFS four-way connectivity.", "verified": true, "reference_solution": "def locate_weeds_cluster(grid):\n    \"\"\"Return the size of the largest 4-directionally connected cluster of 1s in the grid.\n    An empty grid or a grid without 1s yields 0.\n    \"\"\"\n    if not grid or not grid[0]:\n        return 0\n\n    rows, cols = len(grid), len(grid[0])\n    visited = [[False] * cols for _ in range(rows)]\n\n    def bfs(r, c):\n        from collections import deque\n        q = deque([(r, c)])\n        visited[r][c] = True\n        size = 0\n        while q:\n            x, y = q.popleft()\n            size += 1\n            for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n                nx, ny = x + dx, y + dy\n                if 0 <= nx < rows and 0 <= ny < cols and not visited[nx][ny] and grid[nx][ny] == 1:\n                    visited[nx][ny] = True\n                    q.append((nx, ny))\n        return size\n\n    largest = 0\n    for i in range(rows):\n        for j in range(cols):\n            if grid[i][j] == 1 and not visited[i][j]:\n                largest = max(largest, bfs(i, j))\n    return largest", "reference_tests": [{"type": "basic", "inputs": [[[1, 0, 0], [1, 1, 0], [0, 0, 1]]], "output": 3}, {"type": "basic", "inputs": [[[0, 0], [0, 0]]], "output": 0}, {"type": "edge_case", "inputs": [[[1]]], "output": 1}, {"type": "edge_case", "inputs": [[]], "output": 0}, {"type": "edge_case", "inputs": [[[1, 1], [1, 1]]], "output": 4}], "sample_type": "code_synthetic", "shards": [{"shard_id": 4, "shard": "If grid empty or lacks ones then answer should simply be zero"}, {"shard_id": 2, "shard": "Receive a grid of zero and one numbers and output one integer"}, {"shard_id": 3, "shard": "Cells join if they touch up down left or right never diagonally"}, {"shard_id": 1, "shard": "Goal is to report how large the biggest one patch is"}], "task": "code", "task_id": "sharded-synthetic-code-89", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.75, "sharded-all": {"t-gpt-4.1": [1, 1, 0, 1, 0, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "locate_weeds_cluster"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[[1, 0, 0], [1, 1, 0], [0, 0, 1]]\", \"output\": \"3\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[[0, 0], [0, 0]]\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[[1]]\", \"output\": \"1\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[[1, 1], [1, 1]]\", \"output\": \"4\", \"testtype\": \"functional\"}]"}, {"problem_id": 46, "category": "combinatorics", "name": "possible_anagrams_count", "domain": "linguistics", "description": "Count distinct anagrams for word allowing repeated letters, result modulo 1 000 000 007.", "verified": true, "reference_solution": "def possible_anagrams_count(word):\n    MOD = 1_000_000_007\n    n = len(word)\n    # Precompute factorials up to n\n    fact = [1]*(n+1)\n    for i in range(2, n+1):\n        fact[i] = (fact[i-1]*i) % MOD\n    # Count frequency of each character\n    from collections import Counter\n    freq = Counter(word)\n    # Compute denominator as product of factorials of frequencies\n    denom = 1\n    for c in freq.values():\n        denom = (denom * fact[c]) % MOD\n    # Use Fermat's little theorem for modular inverse since MOD is prime\n    inv_denom = pow(denom, MOD-2, MOD)\n    return (fact[n] * inv_denom) % MOD", "reference_tests": [{"type": "basic", "inputs": ["abc"], "output": 6}, {"type": "basic", "inputs": ["aab"], "output": 3}, {"type": "edge_case", "inputs": ["zzzz"], "output": 1}, {"type": "edge_case", "inputs": ["abab"], "output": 6}, {"type": "edge_case", "inputs": [""], "output": 1}], "sample_type": "code_synthetic", "shards": [{"shard_id": 1, "shard": "Count all unique reorderings of the input word"}, {"shard_id": 2, "shard": "If letters repeat they shrink the total count"}, {"shard_id": 4, "shard": "Examples empty string gives one and aab gives three"}, {"shard_id": 3, "shard": "Return the count mod 1000000007 positive number"}], "task": "code", "task_id": "sharded-synthetic-code-46", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "possible_anagrams_count"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"\\\"abc\\\"\", \"output\": \"6\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"\\\"aab\\\"\", \"output\": \"3\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"zzzz\\\"\", \"output\": \"1\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"abab\\\"\", \"output\": \"6\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"\\\"\\\"\", \"output\": \"1\", \"testtype\": \"functional\"}]"}, {"problem_id": 53, "category": "simulation", "name": "meteor_shower_sim", "domain": "astronomy", "description": "Given hourly rates, simulate cumulative meteors over period using random.seed(0) and Poisson assumption via random.poisson not available; instead approximate by rounding rate*random.random().", "verified": true, "reference_solution": "import random\n\ndef meteor_shower_sim(rates):\n    \"\"\"\n    Simulate a meteor shower given hourly expected rates.\n\n    Parameters\n    ----------\n    rates : list of int/float\n        Expected number of meteors per each hour.\n\n    Returns\n    -------\n    list of int\n        Cumulative number of meteors observed up to (and including) each hour.\n\n    Notes\n    -----\n    The Poisson-distributed number of meteors for each hour is approximated by\n    rounding the product of the hourly rate and `random.random()`.\n    A fixed seed (0) is set on every call so that the function is deterministic\n    for the same input.\n    \"\"\"\n    # Ensure deterministic results for the same input\n    random.seed(0)\n\n    cumulative = []\n    total = 0\n    for rate in rates:\n        # Approximate Poisson draw\n        count = round(rate * random.random())\n        total += count\n        cumulative.append(total)\n    return cumulative\n", "reference_tests": [{"type": "basic", "inputs": [[10, 10, 10]], "output": [8, 16, 20]}, {"type": "basic", "inputs": [[1, 2, 3]], "output": [1, 3, 4]}, {"type": "edge_case", "inputs": [[]], "output": []}, {"type": "edge_case", "inputs": [[0, 0, 0]], "output": [0, 0, 0]}, {"type": "basic", "inputs": [[5.5, 2.2]], "output": [5, 7]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 1, "shard": "Simulate meteor shower counts from list of hourly expected rates"}, {"shard_id": 2, "shard": "Use python random module with seed zero for repeatable results"}, {"shard_id": 3, "shard": "Draw each hour by rounding rate times random dot random without Poisson"}, {"shard_id": 4, "shard": "Return running cumulative totals list same length handling empty or zero rates"}], "task": "code", "task_id": "sharded-synthetic-code-53", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.5, "sharded-all": {"t-gpt-4.1": [0, 0, 0, 1, 0, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "meteor_shower_sim"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[10, 10, 10]\", \"output\": \"[8, 16, 20]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[1, 2, 3]\", \"output\": \"[1, 3, 4]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\", \"output\": \"[]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[0, 0, 0]\", \"output\": \"[0, 0, 0]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[5.5, 2.2]\", \"output\": \"[5, 7]\", \"testtype\": \"functional\"}]"}, {"problem_id": 52, "category": "bitwise", "name": "encode_constellation_pattern", "domain": "astronomy", "description": "Represent constellation of up to 16 stars as 16-bit integer where bit i is 1 if star i present. Input list may contain duplicates.", "verified": true, "reference_solution": "def encode_constellation_pattern(stars):\n    \"\"\"Encode a list of star indices (0-15) into a 16-bit integer.\n    Each bit i (0 being least-significant) is set to 1 if star i is present.\n    Duplicates in the input list do not affect the result.\n    \"\"\"\n    pattern = 0\n    for s in stars:\n        # assume valid indices 0-15 as per the problem description\n        pattern |= 1 << s\n    return pattern", "reference_tests": [{"type": "basic", "inputs": [[0, 1, 2]], "output": 7}, {"type": "basic", "inputs": [[3, 3, 3]], "output": 8}, {"type": "edge_case", "inputs": [[]], "output": 0}, {"type": "edge_case", "inputs": [[0, 2, 4, 6, 8, 10, 12, 14]], "output": 21845}, {"type": "edge_case", "inputs": [[15]], "output": 32768}], "sample_type": "code_synthetic", "shards": [{"shard_id": 3, "shard": "For each slot set that bit in a sixteen bit unsigned answer"}, {"shard_id": 1, "shard": "Convert a list of star spots into a single pattern number"}, {"shard_id": 4, "shard": "Example slots zero one two together would yield the value seven"}, {"shard_id": 2, "shard": "Only slots zero through fifteen matter any repeats should be ignored"}], "task": "code", "task_id": "sharded-synthetic-code-52", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "encode_constellation_pattern"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[0, 1, 2]\", \"output\": \"7\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[3, 3, 3]\", \"output\": \"8\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[0, 2, 4, 6, 8, 10, 12, 14]\", \"output\": \"21845\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[15]\", \"output\": \"32768\", \"testtype\": \"functional\"}]"}, {"problem_id": 9, "category": "searching", "name": "find_first_fever", "domain": "healthcare", "description": "Given chronological temperature readings, return earliest index where temperature exceeds 38\u00b0C for two consecutive readings. Return -1 if condition never occurs.", "verified": true, "reference_solution": "def find_first_fever(readings):\n    \"\"\"Return the earliest index where temperature exceeds 38\u00b0C for two consecutive readings.\n    If such a pair doesn't exist, return -1.\n    \"\"\"\n    if not readings or len(readings) < 2:\n        return -1\n    for i in range(len(readings) - 1):\n        if readings[i] > 38 and readings[i + 1] > 38:\n            return i\n    return -1", "reference_tests": [{"type": "basic", "inputs": [[36.5, 38.2, 39.0, 37.8]], "output": 1}, {"type": "basic", "inputs": [[36, 37, 38, 37]], "output": -1}, {"type": "edge_case", "inputs": [[39, 39]], "output": 0}, {"type": "edge_case", "inputs": [[]], "output": -1}, {"type": "edge_case", "inputs": [[38, 38.5, 38.6]], "output": 1}, {"type": "edge_case", "inputs": [[37, 39, 37, 39, 39]], "output": 3}], "sample_type": "code_synthetic", "shards": [{"shard_id": 4, "shard": "Output the index of the first member or minus one if none"}, {"shard_id": 3, "shard": "A fever event is two readings in a row higher than 38"}, {"shard_id": 2, "shard": "Given a chronological list of celsius readings as input"}, {"shard_id": 1, "shard": "Detect earliest consecutive fever events in a timeline of temperatures"}], "task": "code", "task_id": "sharded-synthetic-code-9", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "find_first_fever"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[36.5, 38.2, 39.0, 37.8]\", \"output\": \"1\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[36, 37, 38, 37]\", \"output\": \"-1\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[39, 39]\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\", \"output\": \"-1\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[38, 38.5, 38.6]\", \"output\": \"1\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[37, 39, 37, 39, 39]\", \"output\": \"3\", \"testtype\": \"functional\"}]"}, {"problem_id": 10, "category": "hashing", "name": "anonymize_patient_ids", "domain": "healthcare", "description": "Map patient IDs (strings) to anonymized hex digests using SHA-256, but keep only first 12 characters of each digest. Return list preserving original order.", "verified": true, "reference_solution": "import hashlib\n\ndef anonymize_patient_ids(patient_ids):\n    \"\"\"Return a list with each patient id replaced by the first 12 hex characters\n    of its SHA-256 digest, preserving the original order.\n    \"\"\"\n    return [hashlib.sha256(pid.encode('utf-8')).hexdigest()[:12] for pid in patient_ids]\n", "reference_tests": [{"type": "basic", "inputs": [[""]], "output": ["e3b0c44298fc"]}, {"type": "basic", "inputs": [["a", "abc"]], "output": ["ca978112ca1b", "ba7816bf8f01"]}, {"type": "edge_case", "inputs": [["a", "a"]], "output": ["ca978112ca1b", "ca978112ca1b"]}, {"type": "edge_case", "inputs": [[]], "output": []}, {"type": "basic", "inputs": [["The quick brown fox jumps over the lazy dog"]], "output": ["d7a8fbb307d7"]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 3, "shard": "Hex code comes from hashing each id using SHA two fifty six algorithm"}, {"shard_id": 4, "shard": "Only first twelve hex characters kept and keep ordering exactly unchanged"}, {"shard_id": 2, "shard": "You get a list of ids and must return a list same size"}, {"shard_id": 1, "shard": "Swap every patient id with a non identifying hex code string"}], "task": "code", "task_id": "sharded-synthetic-code-10", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "anonymize_patient_ids"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[\\\"\\\"]\", \"output\": \"[\\\"e3b0c44298fc\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[\\\"a\\\", \\\"abc\\\"]\", \"output\": \"[\\\"ca978112ca1b\\\", \\\"ba7816bf8f01\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[\\\"a\\\", \\\"a\\\"]\", \"output\": \"[\\\"ca978112ca1b\\\", \\\"ca978112ca1b\\\"]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\", \"output\": \"[]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[\\\"The quick brown fox jumps over the lazy dog\\\"]\", \"output\": \"[\\\"d7a8fbb307d7\\\"]\", \"testtype\": \"functional\"}]"}, {"problem_id": 12, "category": "bitwise", "name": "privacy_flag_mask", "domain": "social_media", "description": "Combine list of integer privacy flags by bitwise OR to produce single summary flag. Then clear bit 0 (least significant) if total number of posts is zero.", "verified": true, "reference_solution": "def privacy_flag_mask(flags, total_posts):\n    \"\"\"Combine privacy flags with bitwise OR and clear bit 0 if no posts.\n\n    Args:\n        flags (list[int]): List of integer privacy flags.\n        total_posts (int): Total number of posts.\n\n    Returns:\n        int: Summary privacy flag after processing.\n    \"\"\"\n    # Step 1: Combine all flags via bitwise OR\n    summary = 0\n    for f in flags:\n        summary |= int(f)\n\n    # Step 2: If total_posts is zero, clear least-significant bit\n    if total_posts == 0:\n        summary &= ~1  # clear bit 0\n\n    return summary", "reference_tests": [{"type": "basic", "inputs": [[1, 2, 4], 5], "output": 7}, {"type": "basic", "inputs": [[1, 2, 4], 0], "output": 6}, {"type": "edge_case", "inputs": [[], 3], "output": 0}, {"type": "edge_case", "inputs": [[], 0], "output": 0}, {"type": "edge_case", "inputs": [[3, 8], 0], "output": 10}, {"type": "basic", "inputs": [[16, 32, 1], 12], "output": 49}], "sample_type": "code_synthetic", "shards": [{"shard_id": 2, "shard": "Do a bitwise OR across every flag value"}, {"shard_id": 1, "shard": "Merge many privacy numeric flags into one combined flag"}, {"shard_id": 3, "shard": "When there are zero posts clear bit zero in result"}, {"shard_id": 4, "shard": "Takes flag list and count outputs single summary integer flag"}], "task": "code", "task_id": "sharded-synthetic-code-12", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 0.875, "shuffle-concat-all": {"t-gpt-4.1": [1, 0, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.375, "sharded-all": {"t-gpt-4.1": [1, 0, 0, 0, 1, 0, 0, 1]}}, "acceptable": 1, "metadata": {"func_name": "privacy_flag_mask"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[1, 2, 4]\\n5\", \"output\": \"7\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[1, 2, 4]\\n0\", \"output\": \"6\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\\n3\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\\n0\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[3, 8]\\n0\", \"output\": \"10\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[16, 32, 1]\\n12\", \"output\": \"49\", \"testtype\": \"functional\"}]"}, {"problem_id": 21, "category": "sorting", "name": "gradebook_sort", "domain": "education", "description": "Sort list of tuples (student, score) by descending score, breaking ties by alphabetical student name. Return sorted list.", "verified": true, "reference_solution": "def gradebook_sort(records):\n    \"\"\"Sort a list of (student, score) tuples by descending score.\n    If scores are equal, sort alphabetically by the student's name.\n    Args:\n        records (list[tuple[str, int|float]]): The gradebook records.\n    Returns:\n        list[tuple[str, int|float]]: Sorted list following the criteria.\n    \"\"\"\n    # Using negative score for descending order and name for tie-break in ascending\n    return sorted(records, key=lambda item: (-item[1], item[0]))", "reference_tests": [{"type": "basic", "inputs": [[["Alice", 88], ["Bob", 95], ["Charlie", 90]]], "output": [["Bob", 95], ["Charlie", 90], ["Alice", 88]]}, {"type": "basic", "inputs": [[["Alice", 90], ["Bob", 90], ["Charlie", 85]]], "output": [["Alice", 90], ["Bob", 90], ["Charlie", 85]]}, {"type": "edge_case", "inputs": [[]], "output": []}, {"type": "basic", "inputs": [[["Dave", 72.5], ["Eve", 72.5], ["Frank", 100.0]]], "output": [["Frank", 100.0], ["Dave", 72.5], ["Eve", 72.5]]}, {"type": "edge_case", "inputs": [[["Anna", -10], ["Bella", -5], ["Cara", -5]]], "output": [["Bella", -5], ["Cara", -5], ["Anna", -10]]}], "sample_type": "code_synthetic", "shards": [{"shard_id": 4, "shard": "Return reordered list of the same pairs"}, {"shard_id": 3, "shard": "Higher score comes first equal scores use alphabetical name"}, {"shard_id": 2, "shard": "Each record is name score pair given in list"}, {"shard_id": 1, "shard": "Sort student records by performance then name"}], "task": "code", "task_id": "sharded-synthetic-code-21", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 0.875, "sharded-all": {"t-gpt-4.1": [1, 1, 0, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "gradebook_sort"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[[\\\"Alice\\\", 88], [\\\"Bob\\\", 95], [\\\"Charlie\\\", 90]]\", \"output\": \"[[\\\"Bob\\\", 95], [\\\"Charlie\\\", 90], [\\\"Alice\\\", 88]]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[[\\\"Alice\\\", 90], [\\\"Bob\\\", 90], [\\\"Charlie\\\", 85]]\", \"output\": \"[[\\\"Alice\\\", 90], [\\\"Bob\\\", 90], [\\\"Charlie\\\", 85]]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[]\", \"output\": \"[]\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[[\\\"Dave\\\", 72.5], [\\\"Eve\\\", 72.5], [\\\"Frank\\\", 100.0]]\", \"output\": \"[[\\\"Frank\\\", 100.0], [\\\"Dave\\\", 72.5], [\\\"Eve\\\", 72.5]]\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[[\\\"Anna\\\", -10], [\\\"Bella\\\", -5], [\\\"Cara\\\", -5]]\", \"output\": \"[[\\\"Bella\\\", -5], [\\\"Cara\\\", -5], [\\\"Anna\\\", -10]]\", \"testtype\": \"functional\"}]"}, {"problem_id": 69, "category": "searching", "name": "locate_calm_period", "domain": "weather", "description": "Find earliest contiguous subarray of length k where all wind speeds below threshold. Return starting index or -1.", "verified": true, "reference_solution": "def locate_calm_period(speeds, k, threshold):\n    \"\"\"Return the earliest starting index of a contiguous subarray of length k\n    where every wind speed is strictly less than `threshold`. If no such\n    subarray exists, return -1.\n\n    Parameters\n    ----------\n    speeds : list[int]\n        List of recorded wind speeds.\n    k : int\n        Length of the required subarray.\n    threshold : int\n        Speed threshold that all elements of the subarray must be below.\n    \"\"\"\n    n = len(speeds)\n\n    # Quick rejection cases\n    if k <= 0 or k > n:\n        return -1\n\n    # Count how many of the first window violate the condition\n    bad = sum(1 for i in range(k) if speeds[i] >= threshold)\n    if bad == 0:\n        return 0\n\n    # Slide the window across the array\n    for start in range(1, n - k + 1):\n        # remove the leftmost element of the previous window\n        if speeds[start - 1] >= threshold:\n            bad -= 1\n        # add the new rightmost element\n        if speeds[start + k - 1] >= threshold:\n            bad += 1\n        # if window is valid\n        if bad == 0:\n            return start\n\n    return -1", "reference_tests": [{"type": "basic", "inputs": [[3, 4, 2, 1, 5], 2, 3], "output": 2}, {"type": "basic", "inputs": [[1, 1, 1], 3, 2], "output": 0}, {"type": "edge_case", "inputs": [[4, 5, 6], 1, 4], "output": -1}, {"type": "edge_case", "inputs": [[1, 2], 3, 5], "output": -1}, {"type": "edge_case", "inputs": [[0, 1, 5, 1, 0], 2, 2], "output": 0}], "sample_type": "code_synthetic", "shards": [{"shard_id": 4, "shard": "Return minus one for impossible cases like k bigger than list size"}, {"shard_id": 2, "shard": "Input three things speeds list integer k and threshold speed"}, {"shard_id": 3, "shard": "Output smallest index where k consecutive speeds all below threshold else minus one"}, {"shard_id": 1, "shard": "Need earliest calm stretch in wind speed list length k under limit"}], "task": "code", "task_id": "sharded-synthetic-code-69", "verifications": {"full-avg": 1.0, "full-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "concat-avg": 1.0, "concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "shuffle-concat-avg": 1.0, "shuffle-concat-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}, "sharded-avg": 1.0, "sharded-all": {"t-gpt-4.1": [1, 1, 1, 1, 1, 1, 1, 1]}}, "acceptable": 1, "metadata": {"func_name": "locate_calm_period"}, "public_test_cases": "[{\"type\": \"basic\", \"input\": \"[3, 4, 2, 1, 5]\\n2\\n3\", \"output\": \"2\", \"testtype\": \"functional\"}, {\"type\": \"basic\", \"input\": \"[1, 1, 1]\\n3\\n2\", \"output\": \"0\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[4, 5, 6]\\n1\\n4\", \"output\": \"-1\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[1, 2]\\n3\\n5\", \"output\": \"-1\", \"testtype\": \"functional\"}, {\"type\": \"edge_case\", \"input\": \"[0, 1, 5, 1, 0]\\n2\\n2\", \"output\": \"0\", \"testtype\": \"functional\"}]"}]